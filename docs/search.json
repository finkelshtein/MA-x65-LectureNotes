[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA-365/M65 Lecture Notes",
    "section": "",
    "text": "Overview\nUse the left panel to navigate the website.\nUse search field on the left to find all instances of a term in the Lecture Notes.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "Ch-01.html",
    "href": "Ch-01.html",
    "title": "1  Loss distributions",
    "section": "",
    "text": "mathfn = require('https://bundle.run/mathfn@1.1.0')\n\n\n\n\n\n\n\n\n\n\n\n\nNote1.1 Probability distribution\n\n\n\n\nLet \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) be a probability space.\nA measurable function \\(X:\\Omega\\to\\mathbb{R}\\) is called a random variable.\nThe cummulative distribution function (CDF) of \\(X\\) is a non-decreasing function \\[\nF_X(x)=\\mathbb{P}(X\\leq x)\\in[0,1].\n\\tag{1.1}\\]\nThe probability density function (PDF) (a.k.a. probability density) of \\(X\\) is \\[\nf_X(x)=F'_X(x)\\geq0.\n\\tag{1.2}\\]\nRelation: \\[\n\\mathbb{P}(a\\leq X \\leq b) = \\int_a^b f_X(x)\\,dx=F_X(b)-F_X(a).\n\\tag{1.3}\\]\nThe expectation of \\(X\\) is \\[\n\\mathbb{E}(X) = \\int_{\\mathbb{R}} x\\, f_X(x)\\,dx.\n\\tag{1.4}\\] More generally, for any (measurable) \\(g:{\\mathbb{R}}\\to{\\mathbb{R}}\\), \\(g(X):\\Omega\\to{\\mathbb{R}}\\) is also a random variable, and \\[\n\\mathbb{E}(g(X)) = \\int_{\\mathbb{R}} g(x) f_X(x)\\,dx.\n\\tag{1.5}\\]\n\n\n\n\n\n\n\n\n\nNote1.2 Moments\n\n\n\n\nFor a \\(k\\in\\mathbb{N}\\), the moment of order \\(k\\) of \\(X\\) is \\[\nm_k=m_{k,X}=\\mathbb{E}(X^k)=\\int_{\\mathbb{R}} x^k \\, f_X(x)\\,dx.\n\\tag{1.6}\\]\nThe variance of a random variable \\(X\\) is \\[\n\\begin{align}\n\\mathrm{Var}(X):&= \\mathbb{E}\\bigl((X-\\mathbb{E}(X))^2\\bigr)\\\\\n            & = \\mathbb{E}(X^2)-\\bigl(\\mathbb{E}(X)\\bigr)^2=m_{2,X}-(m_{1,X})^2\n\\end{align}\n\\tag{1.7}\\]\nThe moment generator function (MGM) is \\[\nM_X(t)=\\mathbb{E}(e^{tX})=\\int_{\\mathbb{R}} e^{tx} \\, f_X(x)\\,dx\\geq0.\n\\tag{1.8}\\]\nRelation: \\[\nM_X(t)=1+\\sum_{k=1}^\\infty\\frac{m_k}{k!}t^k.\n\\tag{1.9}\\] and \\[\nm_{k,X}  = M_X^{(k)}(0)\n\\tag{1.10}\\]\n\n\n\n\n\n\n\n\n\nNote1.3 Cheracterisations\n\n\n\nA random variable is uniquely determined by either of CDF, PDF, MGF. Note that the sequence of all moments, in general, does not determine the distribution uniquely (Hamburger moment problem).\n\n\n\n\n\n\n\n\nNote1.4 Conditional characteristics\n\n\n\n\nFor random variables \\(X\\) and \\(Y\\), the \\(\\mathbb{E}(X\\mid Y)\\) (of \\(X\\) given \\(Y\\)) is a random variable measurable with respect to the \\(\\sigma\\)-algebra generated by \\(Y\\) (i.e. by all subsets \\(\\{Y\\leq a\\}\\subset\\Omega\\) for \\(a\\in\\mathbb{R}\\)) such that \\[\n\\mathbb{E}\\bigl(\\mathbb{E}(X\\mid Y)\\bigr) = \\mathbb{E}(X).\n\\tag{1.11}\\]\nIn particular, if \\(Y_1,\\ldots,Y_n\\) makes a partition of \\(\\Omega\\) (i.e. their disjoint union is \\(\\Omega\\)), then \\[\n\\mathbb{E}(X)=\\sum_{i=1}^n \\mathbb{E}(X\\mid Y_i)\\mathbb{P}(Y_i).\n\\tag{1.12}\\]\nThe conditional variance of \\(X\\) given \\(Y\\) is the random variable \\[\n\\mathrm{Var}(X\\mid Y) = \\mathbb{E}\\Bigl(\n      \\bigl(X- \\mathbb{E}(X\\mid Y)\\bigr)^2 \\Bigm\\vert Y \\Bigr)\n\\tag{1.13}\\]\nThe law of total variance is that \\[\n\\mathrm{Var}(X) = \\mathbb{E}\\bigl(\\mathrm{Var}(X\\mid Y)\\bigr) + \\mathrm{Var}\\bigl(\\mathbb{E}(X\\mid Y)\\bigr).\n\\tag{1.14}\\]\n\n\n\n\n\n\n\n\n\nTip1.5 Remark\n\n\n\n\nRecall that functions \\(\\dfrac{1}{1+|x|^\\beta}\\) and \\(\\dfrac{1}{(1+|x|)^\\beta}\\) are integrable on \\({\\mathbb{R}}\\) iff \\(\\beta&gt;1\\).\nNote that if \\(f_X(x)\\) is continuous on \\({\\mathbb{R}}\\), it’s integrable on arbitrary large interval \\([-r,r]\\), \\(r&gt;0\\). Therefore, if there exists \\(A&gt;\\) and \\(r&gt;0\\) such that \\[\n|f_X(x)|\\leq \\frac{A}{1+|x|^\\beta}, \\qquad |x|&gt;r,\n\\tag{1.15}\\] and \\(\\beta&gt;1\\), then indeed, \\(\\int\\limits_{{\\mathbb{R}}}|f_X(x)|\\,dx&lt;\\infty\\).\nAs a result, if \\(\\beta&gt;k+1\\) in (1.15), then the \\(k\\)-th moment \\(m_k\\) in (1.6) is well defined and finite.\nExamples of such probability densities \\(f_X(x)\\) may be, apart from the obvious \\(\\dfrac{1}{1+|x|^\\beta}\\) and \\(\\dfrac{1}{(1+|x|)^\\beta}\\) with \\(\\beta&gt;k+1\\), also the considered below Weibull function \\[\nf_X(x)=e^{-a |x|^b}\n\\tag{1.16}\\] with any positive \\(a,b&gt;0\\).\nMoreover, if in (1.16) \\(b&gt;1\\), then \\(0&lt; M_X(t)&lt;\\infty\\).\n\n\n\n\n\n\n\n\n\nNote1.6 The exponential distribution\n\n\n\nA random variable \\(X:\\Omega\\to{\\mathbb{R}}\\) has the exponential distribution with parameter \\(\\lambda&gt;0\\) if its CDF is \\[\nF(x)=1-e^{-\\lambda x}, \\quad x\\geq0.\n\\tag{1.17}\\]\nHere and below, when we write a restriction on \\(x\\), we mean that function is \\(0\\) otherwise, i.e. here \\(F(x)=0\\) for \\(x&lt;0\\).\nThen the PDF is \\[\nf(x)=\\lambda e^{-\\lambda x}, \\quad x\\geq0.\n\\tag{1.18}\\]\nNext, \\[\n\\mathbb{E}(X)=\\frac1{\\lambda},\n\\tag{1.19}\\] \\[\n\\mathrm{Var}(X)=\\frac1{\\lambda^2}= \\bigl( \\mathbb{E}(X) \\bigr)^2,\n\\tag{1.20}\\] \\[\n\\mathbb{E}(X^2)=\\frac2{\\lambda^2}=2\\bigl( \\mathbb{E}(X) \\bigr)^2.\n\\tag{1.21}\\] The MGM if defined for \\(t&lt;\\lambda\\) only: \\[\nM(t)=\\biggl(1-\\frac{t}{\\lambda}\\biggr)^{-1}=\\frac{\\lambda}{\\lambda-t}.\n\\] The notation is \\[\nX\\sim Exp(\\lambda).\n\\tag{1.22}\\]\n\n\n\n\n\n\nviewof l = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\lambda:` })\n\nviewof xmexp = Inputs.range([1, 100], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nymaxexp = d3.max(d3.range(0, xmexp, 0.01).map(t =&gt; l*Math.exp(-l * t)))\n\nPlot.plot({\n  x: { domain: [-0.1, xmexp] },\n  y: { domain: [-0.1*ymaxexp, ymaxexp*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    Plot.line(\n      d3\n        .range(0, xmexp, 0.1)\n        .map(t =&gt; [\n          t,\n          l*Math.exp(-l * t)\n        ]),{\n        strokeWidth: 3,\n        stroke: \"steelblue\"\n      }\n    ),\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: 0 })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.1: Graph of \\(f(x)=\\lambda e^{-\\lambda x}\\)\n\n\n\n\n\n\n\n\n\nNote1.7 The gamma distribution\n\n\n\nA random variable \\(X:\\Omega\\to{\\mathbb{R}}\\) has the gamma distribution with parameters \\(\\alpha&gt;0\\) and \\(\\lambda&gt;0\\) if its PDF is \\[\nf(x)=\\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1} e^{-\\lambda x}, \\quad x\\geq0.\n\\tag{1.23}\\] Here \\[\n\\Gamma(\\alpha):=\\int_0^\\infty t^{\\alpha-1}e^{-t}\\,dt, \\quad \\alpha&gt;0\n\\tag{1.24}\\] is the gamma function.\nThe following formulas hold: \\[\n\\mathbb{E}(X)=\\frac{\\alpha}{\\lambda},\n\\tag{1.25}\\] \\[\n\\mathbb{E}(X^2)=\\frac{\\alpha+\\alpha^2}{\\lambda^2},\n\\tag{1.26}\\] \\[\n\\mathrm{Var}(X)=\\frac{\\alpha}{\\lambda^2},\n\\tag{1.27}\\] \\[\nM_X(t)=\\biggl(1-\\frac{t}{\\lambda}\\biggr)^{-\\alpha}=\\frac{\\lambda^\\alpha}{(\\lambda-t)^\\alpha}, \\quad t&lt;\\lambda.\n\\tag{1.28}\\] The notation is \\[\nX\\sim \\Gamma(\\alpha,\\lambda).\n\\]\n\n\n\n\n\n\nviewof a = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\alpha:` })\nviewof l2 = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\lambda:` })\nviewof xmgamma = Inputs.range([1, 100], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nfunction gamma(t,alpha,lambda){\n  return ((lambda**alpha)/mathfn.gamma(alpha))*(t**(alpha-1))*Math.exp(-lambda * t);\n}\n\n\nymaxgamma = d3.max(d3.range(0.1, xmgamma, 0.001).map(t =&gt; gamma(t,a,l2)))\n\n\nPlot.plot({\n  x: { domain: [0.1, xmgamma] },\n  y: { domain: [-0.1*ymaxgamma, ymaxgamma*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    Plot.line(\n      d3\n        .range(0,xmgamma, 0.01)\n        .map(t =&gt; [t, gamma(t,a,l2)]),{\n        strokeWidth: 3,\n        stroke: \"steelblue\"\n      }\n    ),\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: 0 })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Graph of \\(f(x)=\\dfrac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1} e^{-\\lambda x}\\)\n\n\n\n\n\n\n\n\n\nNote1.8 The normal distribution\n\n\n\nA random variable \\(X:\\Omega\\to{\\mathbb{R}}\\) has the normal distribution with the mean \\(\\mu\\) and the variance \\(\\sigma^2\\) if \\[\nf_X(x)=\\frac1{\\sigma\\sqrt{2\\pi}}e^{-\\frac1{2\\sigma^2}(x-\\mu)^2}.\n\\tag{1.29}\\] Indeed, \\[\n\\mathbb{E}(X)=\\mu, \\quad \\mathrm{Var}(X)=\\sigma^2.\n\\tag{1.30}\\] The MGF is defined now everywhere: \\[\nM_X(t)=e^{\\mu t +\\frac12 \\sigma^2 t^2}, \\quad t\\in{\\mathbb{R}}.\n\\tag{1.31}\\] Notation \\[\nX\\sim N(\\mu,\\sigma^2).\n\\]\n\n\n\n\n\n\nviewof mu = Inputs.range([-0.7*xmgauss, 0.7*xmgauss], { value: 0, step: 0.001, label: tex`\\mu:` })\nviewof sigma = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\sigma:` })\nviewof xmgauss = Inputs.range([1, 100], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nfunction gauss(t,mu,sigma){\n  return Math.exp(-(1/(2*sigma**2))*(t-mu)**2)/(sigma*Math.sqrt(2*Math.PI));\n}\n\nymaxgauss = d3.max(d3.range(-xmgauss, xmgauss, 0.01).map(t =&gt; gauss(t,mu,sigma)))\n\nPlot.plot({\n  x: { domain: [-xmgauss, xmgauss] },\n  y: { domain: [-ymaxgauss*0.1, ymaxgauss*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    Plot.line(\n      d3\n        .range(-xmgauss, xmgauss, 0.01)\n        .map(t =&gt; [t, gauss(t,mu,sigma)]),{\n        strokeWidth: 3,\n        stroke: \"steelblue\"\n      }\n    ),\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: 0 })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.3: Graph of \\(f_X(x)=\\dfrac1{\\sigma\\sqrt{2\\pi}}e^{-\\frac1{2\\sigma^2}(x-\\mu)^2}\\)\n\n\n\n\n\n\n\n\n\nNote1.9 The lognormal distribution\n\n\n\nA random variable \\(X:\\Omega\\to{(0,\\infty)}\\) has the lognormal distribution with parameters \\(\\mu\\) and \\(\\sigma^2\\) iff \\[\n\\ln X \\sim N(\\mu,\\sigma^2).\n\\tag{1.32}\\] Equivalently, if \\(Z\\sim N(\\mu,\\sigma^2)\\), then \\(X=e^Z\\).\nNotation: \\[\nX\\sim\\ln N (\\mu,\\sigma^2).\n\\]\nThen \\[\n\\mathbb{E}(X)= e^{\\mu+\\frac12\\sigma^2},\n\\tag{1.33}\\] \\[\n\\mathrm{Var}(X)=e^{2\\mu+\\sigma^2}\\left( e^{\\sigma^2} -1\\right),\n\\tag{1.34}\\] \\[\nf_X(x)= \\frac{1}{x\\sigma\\sqrt{2\\pi}}\\exp\\biggl(- \\frac{(\\ln x -\\mu)^2}{2\\sigma^2}\\biggr)\n\\tag{1.35}\\]\n\n\n\n\n\n\nviewof mu2 = Inputs.range([0, xmloggauss*0.5], { value: 0, step: 0.001, label: tex`\\mu:` })\nviewof sigma2 = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\sigma:` })\nviewof xmloggauss = Inputs.range([1, 100], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nfunction loggauss(t,mu,sigma){\n  return Math.exp(-(1/(2*sigma**2))*(Math.log(t)-mu)**2)/(t*sigma*Math.sqrt(2*Math.PI));\n}\n\nymaxloggauss = d3.max(d3.range(0.01, xmloggauss, 0.001).map(t =&gt; loggauss(t,mu2,sigma2)))\n\nPlot.plot({\n  x: { domain: [0.1,xmloggauss] },\n  y: { domain: [-ymaxloggauss*0.1,  ymaxloggauss*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    Plot.line(\n      d3\n        .range(0.1, xmloggauss, 0.01)\n        .map(t =&gt; [t, loggauss(t,mu2,sigma2)]),{\n        strokeWidth: 3,\n        stroke: \"steelblue\"\n      }\n    ),\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: 0 })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.4: Graph of \\(f_X(x)= \\dfrac{1}{x\\sigma\\sqrt{2\\pi}}\\exp\\biggl(- \\frac{(\\ln x -\\mu)^2}{2\\sigma^2}\\biggr)\\)\n\n\n\n\n\n\n\n\n\nNote1.10 Pareto distribution\n\n\n\nA random variable \\(X\\) has the two-parameter Pareto distribution with parameters \\(\\alpha&gt;0\\) and \\(\\lambda&gt;0\\), if \\[\nF_X(x)=1-\\biggl(\\frac{\\lambda}{\\lambda+x}\\biggr)^\\alpha, \\qquad x\\geq0.\n\\tag{1.36}\\] Notation \\(X\\sim Pa(\\alpha,\\lambda)\\).\nThen \\[\nf_X(x)=\\frac{\\alpha\\lambda^\\alpha}{(\\lambda+x)^{\\alpha+1}},\n\\tag{1.37}\\] and, {for \\(\\alpha&gt;1\\)}, \\[\n\\mathbb{E}(X)=\\frac{\\lambda}{\\alpha-1}\n\\tag{1.38}\\] A modification of the Pareto distribution is the Burr distribution with additional parameter \\(\\gamma&gt;0\\) \\[\nF_{Burr}(x)=F_{Pareto}(x^\\gamma)=1-\\biggl(\\frac{\\lambda}{\\lambda+x^\\gamma}\\biggr)^\\alpha.\n\\tag{1.39}\\]\n\n\n\n\n\n\nviewof ap = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`\\alpha:` })\nviewof lp = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`\\lambda:` })\nviewof xmpareto = Inputs.range([1, 100], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nfunction pareto(t,alpha,lambda){\n  return alpha*lambda**alpha*(t+lambda)**(-1-alpha);\n}\n\nymaxpareto = d3.max(d3.range(0.1, xmpareto, 0.01).map(t =&gt; pareto(t,ap,lp)))\n\nPlot.plot({\n  x: { domain: [0.1,xmpareto] },\n  y: { domain: [-ymaxpareto*0.1,  ymaxpareto*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    Plot.line(\n      d3\n        .range(0.1, xmpareto, 0.01)\n        .map(t =&gt; [t, pareto(t,ap,lp)]),{\n        strokeWidth: 3,\n        stroke: \"steelblue\"\n      }\n    ),\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: 0 })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.5: Graph of \\(f_X(x)= \\dfrac{\\alpha\\lambda^\\alpha}{(\\lambda+x)^{\\alpha+1}}\\)\n\n\n\n\n\n\n\n\n\nNote1.11 The Weibull distribution\n\n\n\nFor \\(a&gt;0\\), \\(b&gt;0\\), we denote \\(X\\sim W(a,b)\\) iff \\[\nF_X(x)=1-e^{-a x^b},\n\\tag{1.40}\\] \\[\nf_X(x)=ab x^{b-1}e^{-a x^b},\n\\tag{1.41}\\] \\[\n\\mathbb{E}(X)=\\Gamma\\biggl(1+\\frac{1}{b}\\biggr)a^{-\\frac{1}{b}}.\n\\tag{1.42}\\]\n\n\n\n\n\n\nviewof aw = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`a:` })\nviewof bw = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`b:` })\nviewof xmweibull = Inputs.range([1, 100], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nfunction weibull(t,a,b){\n  return a*b*t**(b-1)*Math.exp(-a*t**b);\n}\n\nymaxweibull = d3.max(d3.range(0.1, xmweibull, 0.01).map(t =&gt; weibull(t,aw,bw)))\n\nPlot.plot({\n  x: { domain: [0.1,xmweibull] },\n  y: { domain: [-ymaxweibull*0.1,  ymaxweibull*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    Plot.line(\n      d3\n        .range(0.1, xmweibull, 0.01)\n        .map(t =&gt; [t,  weibull(t,aw,bw)]),{\n        strokeWidth: 3,\n        stroke: \"steelblue\"\n      }\n    ),\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: 0 })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.6: Graph of \\(f_X(x)= ab x^{b-1}e^{-a x^b}\\)\n\n\n\n\n\n\nimport {legend, swatches} from \"@d3/color-legend\"\n\n\nviewof xmin = Inputs.range([0.1, xmax*0.9], { value: 0.1, step: 0.1, label: tex`x_\\mathrm{min}` })\n\nviewof xmax = Inputs.range([1,1000], { value: 10, step: 1, label: tex`x_\\mathrm{max}` })\n\nviewof lexp = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\lambda_{Exp}:` })\n\nviewof agamma = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\alpha_{Gamma}:` })\nviewof lgamma = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\lambda_{Gamma}:` })\n\nviewof muG = Inputs.range([0.1, 10], { value: 0, step: 0.001, label: tex`\\mu_{\\mathcal{N}}:` })\nviewof sigmaG = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\sigma_{\\mathcal{N}}:` })\n\nviewof logmu = Inputs.range([0.1, 10], { value: 0, step: 0.001, label: tex`\\mu_{\\log\\mathcal{N}}:` })\nviewof logsigma = Inputs.range([0.1, 10], { value: 1, step: 0.001, label: tex`\\sigma_{\\log\\mathcal{N}}:` })\n\nviewof apareto = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`\\alpha_{Pareto}:` })\n\nviewof lpareto = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`\\lambda_{Pareto}:` })\n\nviewof aweibull = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`a_{Weibull}:` })\n\nviewof bweibull = Inputs.range([0.1, 10], { value: 0.1, step: 0.001, label: tex`b_{Weibull}:` })\nviewof isExp = Inputs.toggle({label: \"exponential\",value: true})\n\nviewof isGamma = Inputs.toggle({label: \"gamma\",value: true})\n\nviewof isGauss = Inputs.toggle({label: \"normal\",value: true})\n\nviewof isLogGauss = Inputs.toggle({label: \"lognormal\",value: true})\n\nviewof isPareto = Inputs.toggle({label: \"Pareto\",value: true})\n\nviewof isWeibull = Inputs.toggle({label: \"Weibull\",value: true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyexp = d3.max(d3.range(xmin, xmax, 0.01).map(t =&gt; lexp*Math.exp(-lexp * t)))\nygamma = d3.max(d3.range(xmin, xmax, 0.001).map(t =&gt; gamma(t,agamma,lgamma)))\nygauss = d3.max(d3.range(xmin, xmax, 0.01).map(t =&gt; gauss(t,mu,sigma)))\nyloggauss = d3.max(d3.range(xmin, xmax, 0.001).map(t =&gt; loggauss(t,logmu,logsigma)))\nypareto = d3.max(d3.range(xmin, xmax, 0.01).map(t =&gt; pareto(t,apareto,lpareto)))\nyweibull = d3.max(d3.range(xmin, xmax, 0.01).map(t =&gt; weibull(t,aweibull,bweibull)))\n\ntfull = d3.max([isExp?yexp:0, isGamma?ygamma:0, isGauss?ygauss:0, isPareto?ypareto:0, isWeibull?yweibull:0, isLogGauss?yloggauss:0])\n\nPlot.plot({\n  x: { domain: [xmin, xmax] },\n  y: { domain: [-tfull*0.1,  tfull*1.2] },\n  width: 640,\n  height: 240,\n  marks: [\n    (isExp == true)?Plot.line(\n      d3\n        .range(xmin, xmax, 0.01)\n        .map(t =&gt; [t, lexp*Math.exp(-lexp*t)]),{\n        strokeWidth: 3,\n        stroke: d3.schemeCategory10[0]\n      }\n    ):Plot.line(\n      d3\n        .range(0, 0.01, 0.01)\n        .map(t =&gt; [t, t]),{\n        strokeWidth: 0,\n        stroke: d3.schemeCategory10[0]\n      }\n    ),\n    (isGamma == true)?Plot.line(\n      d3\n        .range(xmin, xmax, 0.01)\n        .map(t =&gt; [t, gamma(t,agamma,lgamma)]),{\n        strokeWidth: 3,\n        stroke: d3.schemeCategory10[1]\n      }\n    ):Plot.line(\n      d3\n        .range(0, 0.01, 0.01)\n        .map(t =&gt; [t, t]),{\n        strokeWidth: 0,\n        stroke: d3.schemeCategory10[0]\n      }\n    ),\n    (isGauss == true)?Plot.line(\n      d3\n        .range(xmin, xmax, 0.01)\n        .map(t =&gt; [t, gauss(t,muG,sigmaG)]),{\n        strokeWidth: 3,\n        stroke: d3.schemeCategory10[2]\n      }\n    ):Plot.line(\n      d3\n        .range(0, 0.01, 0.01)\n        .map(t =&gt; [t, t]),{\n        strokeWidth: 0,\n        stroke: d3.schemeCategory10[0]\n      }\n    ),\n    (isLogGauss == true)?Plot.line(\n      d3\n        .range(xmin, xmax, 0.01)\n        .map(t =&gt; [t, loggauss(t,logmu,logsigma)]),{\n        strokeWidth: 3,\n        stroke: d3.schemeCategory10[3]\n      }\n    ):Plot.line(\n      d3\n        .range(0, 0.01, 0.01)\n        .map(t =&gt; [t, t]),{\n        strokeWidth: 0,\n        stroke: d3.schemeCategory10[0]\n      }\n    ),\n    (isPareto == true)?Plot.line(\n      d3\n        .range(xmin, xmax, 0.01)\n        .map(t =&gt; [t, pareto(t,apareto,lpareto)]),{\n        strokeWidth: 3,\n        stroke: d3.schemeCategory10[4]\n      }\n    ):Plot.line(\n      d3\n        .range(0, 0.01, 0.01)\n        .map(t =&gt; [t, t]),{\n        strokeWidth: 0,\n        stroke: d3.schemeCategory10[0]\n      }\n    ),\n    (isWeibull == true)?Plot.line(\n      d3\n        .range(xmin, xmax, 0.01)\n        .map(t =&gt; [t,  weibull(t,aweibull,bweibull)]),{\n        strokeWidth: 3,\n        stroke: d3.schemeCategory10[5]\n      }\n    ):Plot.line(\n      d3\n        .range(0, 0.01, 0.01)\n        .map(t =&gt; [t, t]),{\n        strokeWidth: 0,\n        stroke: d3.schemeCategory10[0]\n      }\n    ),\n      Plot.ruleX([xmin]),\n      Plot.ruleY([0]),\n      Plot.axisX({ y: 0 }),\n      Plot.axisY({ x: xmin })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nswatches({\n  color: d3.scaleOrdinal([tex`\\displaystyle f_X(x)=\\lambda e^{-\\lambda x}`, tex`\\displaystyle f_X(x)=\\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1} e^{-\\lambda x}`, tex`\\displaystyle f_X(x)=\\frac1{\\sigma\\sqrt{2\\pi}}e^{-\\frac1{2\\sigma^2}(x-\\mu)^2}`, tex`\\displaystyle f_X(x)= \\frac{1}{x\\sigma\\sqrt{2\\pi}}\\exp\\biggl(- \\frac{(\\ln x -\\mu)^2}{2\\sigma^2}\\biggr)`, tex`\\displaystyle f_X(x)=\\frac{\\alpha\\lambda^\\alpha}{(\\lambda+x)^{\\alpha+1}}`, tex`\\displaystyle f_X(x)=ab x^{b-1}e^{-a x^b}`], d3.schemeCategory10)\n    })\n\n\n\n\n\n\n\n\nFigure 1.7: Comparison of right tails for the density functions\n\n\n\n\n\n\n\n\n\nNote1.12 Likelihood\n\n\n\nLet \\(X:\\Omega\\to{\\mathbb{R}}\\) be a random variable whose distribution depends on a parameter \\(\\theta\\in{\\mathbb{R}}\\).\nSuppose that we observe the data \\(x_1,\\ldots,x_n\\) which is the output of this random variable \\(X\\) in course of \\(n\\) independent trials.\nIn other words, we can say that we observe that i.i.d.r.v. \\(X_1,\\ldots, X_n\\) with \\(X_i\\sim X\\), \\(1\\leq i\\leq n\\), take certain values: \\(X_1=x_1,\\ldots, X_n=x_n\\).\nThe likelihood, or likelihood function, is the function \\(\\mathcal{L}(\\theta)=\\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n)\\) of the unknown parameter \\(\\theta\\) (given the observed data \\(x_1,\\ldots,x_n\\)) which is equal to:\n\n(if \\(X\\) is a discrete random variable) the probability to observe this data (given the value of the parameter \\(\\theta\\)): \\[\n\\begin{aligned}\n\\mathcal{L}(\\theta)&=\\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n)\\\\\n:&=\\mathbb{P}(X_1=x_1,\\ldots,X_n=x_n\\mid \\theta)\n\\\\&= \\mathbb{P}(X_1=x_1\\mid \\theta)\\ldots \\mathbb{P}(X_n=x_n\\mid \\theta).\n\\end{aligned}\n\\tag{1.43}\\]\n(if \\(X\\) is a continuous random variable with the PDF \\(f_X(x)=f_X(x\\mid\\theta)\\)) \\[\n\\begin{aligned}\n\\mathcal{L}(\\theta)&=\\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n)\\\\\n:&=f_X(x_1\\mid\\theta)f_X(x_2\\mid\\theta)\\ldots f_X(x_n\\mid\\theta).\n\\end{aligned}\n\\tag{1.44}\\]\n\n\n\n\n\n\n\n\n\nNote1.13 Maximum likelihood estimator\n\n\n\nThe maximum likelihood estimator\\(\\theta_*\\) of the parameter \\(\\theta\\) is the argument of the maximum of the likelihood function: \\[\n\\theta_*=\\mathop{\\mathrm{argmax}}_\\theta\\mathcal{L}(\\theta),\n\\tag{1.45}\\] that means that \\[\n\\mathcal{L}(\\theta_*) = \\max_{\\theta}\\mathcal{L}(\\theta).\n\\tag{1.46}\\]\nThe standard approach to find \\(\\theta_*\\) is to consider the log-likelihood function \\[\nL(\\theta):=L(\\theta\\mid x_1,\\ldots,x_n)=\\ln \\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n).\n\\tag{1.47}\\]\nThus, in the discrete case, \\[\nL(\\theta) = \\ln \\mathbb{P}(X_1=x_1\\mid \\theta)+ \\ldots + \\ln \\mathbb{P}(X_n=x_n\\mid \\theta),\n\\tag{1.48}\\] whereas, in the continuous case \\[\nL(\\theta) = \\ln f_X(x_1\\mid\\theta)+ \\ldots + \\ln f_X(x_n\\mid\\theta),\n\\tag{1.49}\\]\nThen \\(\\theta_*\\) is the point of maximum for both \\(\\mathcal{L}\\) and \\(L\\): \\[\n\\theta_*=\\mathop{\\mathrm{argmax}}_\\theta L(\\theta)=\\mathop{\\mathrm{argmax}}_\\theta\\mathcal{L}(\\theta).\n\\tag{1.50}\\]\n\n\n\n\n\n\n\n\nWarning1.14 Example: Discrete case\n\n\n\nLet \\(X\\sim Po(\\lambda)\\), i.e. \\[\n\\mathbb{P}(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}, \\quad k\\geq0.\n\\] Suppose we have a sample of \\(n\\) values of \\(X\\): \\(k_1,\\ldots,k_n\\), and we want to estimate \\(\\lambda\\) (here \\(\\theta=\\lambda\\)). Then \\[\n\\begin{aligned}\n\\mathcal{L}(\\lambda)&=\\mathbb{P}(X=k_1\\mid\\lambda)\\ldots \\mathbb{P}(X=k_n\\mid\\lambda)\\\\\n& = \\frac{\\lambda^{k_1}}{k_1!}e^{-\\lambda}\\cdot\\ldots\\cdot \\frac{\\lambda^{k_n}}{k_n!}e^{-\\lambda}\\\\\n& = \\underbrace{\\frac{1}{k_1!\\ldots k_n!}}_{=: c&gt;0}\\lambda^{k_1+\\ldots+k_n}e^{-\\lambda n},\n\\end{aligned}\n\\] and therefore, \\[\n\\begin{aligned}\nL(\\lambda)&=\\ln\\mathcal{L}(\\lambda)\n\\\\& = \\ln c + (k_1+\\ldots+k_n)\\ln\\lambda-\\lambda n.\n\\end{aligned}\n\\] Then \\[\nL'(\\lambda) = \\frac{k_1+\\ldots+k_n}{\\lambda}-n,\n\\] and hence, \\(L'(\\lambda)=0\\) iff \\[\n{\\lambda = \\frac{k_1+\\ldots+k_n}{n}}.\n\\]\nSince \\[\nL''(\\lambda) = (L'(\\lambda))'=-\\frac{k_1+\\ldots+k_n}{\\lambda^2}&lt;0,\n\\] the found value \\(\\lambda_* = \\frac{k_1+\\ldots+k_n}{n}\\) is the point of maximum of \\(L\\), hence, it is the maximum likelihood estimator for the parameter \\(\\lambda\\).\n\n\n\n\n\n\n\n\nTip1.15 Remark: Relation to the LLN\n\n\n\nNote that, by the law of large numbers (LLN), if \\(X_i\\sim X\\sim Po(\\lambda)\\), \\(i\\in\\mathbb{N}\\), then \\[\n\\frac{X_1+\\ldots+X_n}{n} \\to \\mathbb{E}(X)=\\lambda, \\qquad n\\to\\infty.\n\\] In other words, the maximum likelihood estimator converges to the theoretical value is the size of the sample converges to infinity.\n\n\n\n\n\n\n\n\nWarning1.16 Example: Continuous case\n\n\n\nLet \\(X\\sim Exp(\\lambda)\\). Suppose we have a sample of \\(n\\) values of \\(X\\): \\(x_1,\\ldots,x_n\\). Then \\[\n\\begin{aligned}\n\\mathcal{L}(\\lambda) &= f_X(x_1\\mid \\lambda)\\ldots f_X(x_n\\mid \\lambda)\\\\\n&=\\lambda e^{-\\lambda x_1}\\ldots \\lambda e^{-\\lambda x_n}= \\lambda^n e^{-\\lambda(x_1+\\ldots +x_n)}.\n\\end{aligned}\n\\]\nTherefore, \\[\n\\begin{aligned}\nL(\\lambda)&= \\ln \\mathcal L(\\lambda)\n\\\\&= n \\ln \\lambda - \\lambda(x_1+\\ldots +x_n),\n\\end{aligned}\n\\] so \\(L'(\\lambda)=0\\) iff \\[\n\\begin{gathered}\n\\frac{n}{\\lambda} -(x_1+\\ldots +x_n)=0,\\\\\n{\\lambda_*= \\frac{n}{x_1+\\ldots +x_n}}.\n\\end{gathered}\n\\] Note that \\(L''(\\lambda)=-\\dfrac{n}{\\lambda^2}\\), in particular, \\(L''(\\lambda_*)&lt;0\\), i.e. \\(\\lambda_*\\) is indeed the maximum likelihood estimator for the parameter \\(\\lambda\\).\nFinally, note that if \\(X_i\\sim X\\sim Exp(\\lambda)\\), then, by LLN, \\[\n\\frac{X_1+\\ldots+X_n}{n}\\to \\mathbb{E}(X)=\\frac{1}{\\lambda}, \\qquad n\\to\\infty.\n\\]\n\n\n\n\n\n\n\n\nNote1.17 The method of moments\n\n\n\nIf the number of parameters is bigger than \\(1\\), the maximum likelihood estimation may be challenging as one would need to find the point of maximum for a function of several variables (though it can be still effectively done numerically).\nAnother method to estimate unknown parameters of the distribution is the method of moments. Namely, assuming that we have a sample of \\(n\\) values \\(x_1,\\ldots,x_n\\) of a random variable \\(X\\) which is believed to be followed a probability distribution which depends on \\(k\\) unknown parameters \\(\\theta=(\\theta_1,\\ldots,\\theta_k)\\).\nThen, we consider the first \\(k\\) moments of the random variable \\(X\\) (i.e. the moments of the population): \\[\nm_j = \\mathbb{E}(X^j\\mid \\theta), \\qquad 1\\leq j\\leq k.\n\\]\nNext, for the given data \\(x_1,\\ldots,x_n\\), we consider \\(k\\) averaged moments (i.e. the moments of the sample): \\[\n\\overline{m}_j = \\frac{1}{n}\\sum_{l=1}^n x_l ^j, \\qquad 1\\leq j\\leq k.\n\\]\nAfter this, we need to equate \\(k\\) quantities: \\[\nm_j = \\overline{m}_j, \\qquad 1\\leq j\\leq k,\n\\] to determine \\(k\\) unknown parameters \\(\\theta_1,\\ldots,\\theta_k\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Loss distributions</span>"
    ]
  },
  {
    "objectID": "Ch-02.html",
    "href": "Ch-02.html",
    "title": "2  Extreme value theory",
    "section": "",
    "text": "Note2.1 Maximum values\n\n\n\nLet \\(X_1,\\ldots,X_n\\) be independent identically distributed random variables (i.i.d. r.v.) with the cumulative distribution function \\(F(x)=F_X(x)\\). Denote \\[\nX_M=X_{M,n}= \\max\\{X_1,\\ldots,X_n\\}.\n\\tag{2.1}\\] Then \\[\n\\begin{aligned}\n\\mathbb{P}(X_M\\leq x) &= \\mathbb{P}(X_1\\leq x, \\ldots, X_n\\leq x) \\\\\n&= \\mathbb{P}(X_1\\leq x) \\ldots \\mathbb{P}(X_n\\leq x) \\\\\n&= \\bigl(\\mathbb{P}(X\\leq x)\\bigr)^n = \\bigl( F(x) \\bigr)^n.\n\\end{aligned}\n\\tag{2.2}\\] We can attempt to standardise the values of \\(X_M\\): consider, for some \\(\\alpha_n&gt;0\\) and \\(\\beta_n\\in\\mathbb{R}\\), \\[\n\\begin{aligned}\n\\mathbb{P}\\biggl(\\frac{X_M-\\alpha_n}{\\beta_n}\\leq x\\biggr) &=\\mathbb{P}(X_M\\leq \\beta_n x + \\alpha_n)\\\\\n& = \\bigl(F(\\beta_n x + \\alpha_n)\\bigr)^n.\n\\end{aligned}\n\\tag{2.3}\\]\n\n\n\n\n\n\n\n\nImportant2.2 Theorem: Extreme value theorem (Fisher–Tippett–Gnedenko theorem)\n\n\n\nIf there exists \\(\\alpha_n&gt;0\\) and \\(\\beta_n\\), such that there exists \\[\nG(x):= \\lim_{n\\to\\infty}\\bigl(F(\\beta_n x + \\alpha_n)\\bigr)^n\n\\tag{2.4}\\] such that \\(G(x)\\) is a non-degenerate cumulative distribution function (i.e. \\(G(x)\\) is not simultaneously identically equal to \\(0\\) for all \\(x&lt;x_1\\) and identically equal to \\(1\\) for all \\(x&gt;x_1\\) with some \\(x_1\\)), then this limiting function \\(G(x)\\) may have only one of the two following forms :\n\neither, for some \\(\\gamma\\neq0\\), \\(a,b\\in\\mathbb{R}\\) \\[\nG(x):=G_\\gamma(x) := \\exp\\Biggl(-\\biggl(1+\\gamma \\frac{x-a}{b} \\biggr)^{-\\frac{1}{\\gamma}}\\Biggr),\n\\tag{2.5}\\]\nor \\[\nG(x):=G_0(x):=\\exp\\Biggl(-\\exp\\biggl(-\\frac{x-a}{b} \\biggr)\\Biggr).\n\\tag{2.6}\\]\n\nNote that, for \\(\\gamma&lt;0\\), \\(G_\\gamma(x)\\) corresponds to a Weibull distribution. For \\(\\gamma&gt;0\\), the corresponding distribution is called Fr'echet distribution, and for \\(\\gamma=0\\), it’s called Gumbel distribution.\n\n\n\n\n\n\n\n\n\n\\(G(x)\\)\nWeibull\n\\(\\gamma&lt;0\\)\nGumbel\n\\(\\gamma=0\\)\nFr’echet\n\\(\\gamma&gt;0\\)\n\n\n\\(F(x)\\)\nUniform\nBeta\nExponential\nGamma\nLog-normal\nNormal\nWeibull\nBurr\nPareto\n\\(t\\)\nLog-gamma\n\n\n\\(x\\)\n\\(x&lt;a-\\dfrac{b}{\\gamma}\\)\n\\(\\mathbb{R}\\)\n\\(x&gt;a-\\dfrac{b}{\\gamma}\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Extreme value theory</span>"
    ]
  },
  {
    "objectID": "Ch-03.html",
    "href": "Ch-03.html",
    "title": "3  Copulas",
    "section": "",
    "text": "Caution3.1 Definition: Joint distribution\n\n\n\nLet \\(X:\\Omega\\to\\mathbb{R}\\) and \\(Y:\\Omega\\to\\mathbb{R}\\) be two random variables on the same probability space \\((\\Omega,\\mathcal{A},\\mathbb{P})\\). The joint (cummulative) distribution function (joint CDF) of \\(X\\) and \\(Y\\) is \\[\nF_{X,Y}(x,y):=\\mathbb{P}(X\\leq x, Y\\leq y).\n\\tag{3.1}\\] It can be naturally extended to multivariate case: if \\(X_1,\\ldots,X_N:\\Omega\\to\\mathbb{R}\\), then \\[\nF_{X_1,\\ldots,X_N}(x_1,\\ldots,x_N):= \\mathbb{P}(X_1\\leq x_1,\\ldots,X_N\\leq x_N).\n\\tag{3.2}\\] If \\(X\\) and \\(Y\\) are continuous, the joint probability density function (joint PDF, a.k.a. joint density) is \\[\nf_{X,Y}(x,y)=\\frac{\\partial^2}{\\partial x\\partial y} F_{X,Y}(x,y).\n\\tag{3.3}\\]\n\n\n\n\n\n\n\n\nCaution3.2 Definition: Marginal distribution\n\n\n\nLet \\(F_{X,Y}\\) be the joint CDF of \\(X\\) and \\(Y\\). Then CDFs of \\(X\\) and \\(Y\\), \\(F_X\\) and \\(F_Y\\), are called marginal distributions of \\(F_{X,Y}\\). The main relation between them is: \\[\n\\begin{aligned}\nF_X(x)&=\\lim_{y\\to\\infty} F_{X,Y}(x,y)=:F_{X,Y}(x,\\infty), \\\\\nF_Y(y)&=\\lim_{x\\to\\infty} F_{X,Y}(x,y)=:F_{X,Y}(\\infty,y).\n\\end{aligned}\n\\tag{3.4}\\]\n\n\n\n\n\n\n\n\nNote3.3 Further relations\n\n\n\nThe following relations hold: \\[\nF_{X,Y}(x,y) = \\int_{-\\infty}^x \\int_{-\\infty}^y f_{X,Y}(u,v)\\,dv\\,du;\n\\tag{3.5}\\] \\[\nf_X(x)  = \\int_{\\mathbb{R}} f_{X,Y}(x,y)\\,dy,\n\\tag{3.6}\\] \\[\nf_Y(x)  = \\int_{\\mathbb{R}} f_{X,Y}(x,y)\\,dx.\n\\tag{3.7}\\]\n\n\n\n\n\n\n\n\nCaution3.4 Definition: Copula\n\n\n\nLet \\(X\\) and \\(Y\\) be random variables with the joint CDF \\(F_{X,Y}\\). The copula of \\(X\\) and \\(Y\\) is a function \\(C_{X,Y}:[0,1]\\times[0,1]\\to[0,1]\\) such that \\[\nC_{X,Y}\\bigl[ F_X(x),F_Y(y) \\bigr] = F_{X,Y}(x,y).\n\\tag{3.8}\\] In other words, \\[\nC_{X,Y}[u,v] = F_{X,Y}\\bigl( F_X^{-1}(u), F_Y^{-1}(v) \\bigr)\n\\tag{3.9}\\] Note that \\(F_X^{-1}\\) and \\(F_Y^{-1}\\) are well-defined almost everywhere as \\(F_X\\) and \\(F_Y\\) are non-decreasing functions. Similarly, for random variables \\(X_1\\), , \\(X_N\\), \\[\nC_{X_1,\\ldots,X_N}[u_1,\\ldots,u_N] = F_{X_1,\\ldots,X_N}\\bigl( F_{X_1}^{-1}(u_1), \\ldots, F_{X_N}^{-1}(u_N) \\bigr).\n\\tag{3.10}\\]\n\n\n\n\n\n\n\n\nNote3.5 Properties of copulas\n\n\n\n\\(C_{X,Y}[u,v]\\) is a function non-decreasing in \\(u\\) and non-decreasing in \\(v\\), such that \\[\n0\\leq C_{X,Y}[u,v]\\leq 1,\n\\tag{3.11}\\] \\[\nC_{X,Y}[u,1]=u,\n\\tag{3.12}\\] \\[\nC_{X,Y}[1,v]=v,\n\\tag{3.13}\\] \\[\nC_{X,Y}[u,0]=C_{X,Y}[0,v]=0\n\\tag{3.14}\\] We can also introduce the copula density function: \\[\nc_{X,Y}[u,v]=\\frac{\\partial^2}{\\partial u\\partial v}C_{X,Y}[u,v],\n\\tag{3.15}\\] then \\[\nc_{X,Y}\\bigl[F_X(x),F_Y(y)\\bigr] = \\frac{f_{X,Y}(x,y)}{f_X(x)\\, f_Y(y)}.\n\\tag{3.16}\\]\n\n\n\n\n\n\n\n\nImportant3.6 Theorem: Sklar’s theorem\n\n\n\nCopulas always exist and, for continuous random variables, are unique.\n\n\n\n\n\n\n\n\nNote3.7 Fundamental copulas\n\n\n\n\nIndependence (or product) copula. Consider \\(C[u,v]=uv\\), then \\[\nF_{X,Y}(x,y)=C[F_X(x),F_Y(y)]=F_X(x)F_Y(y),\n\\] i.e. \\(X\\) and \\(Y\\) are independent random variables.\nCo-monotonic (or minimum) copula. Consider \\(C[u,v]=\\min\\{u,v\\}\\). A typical example: \\(Y=X+\\mathrm{const}\\).\nCounter-monotonic (or maximum) copula. Consider \\(C[u,v]=\\max\\{u+v-1,0\\}\\). A typical example \\(Y=-X\\).\n\n\n\n\n\n\n\n\n\nImportant3.8 Theorem: Fréchet–Hoeffding copula bounds\n\n\n\nFor any copula \\(C:[0,1]\\times[0,1]\\to[0,1]\\), \\[\n\\max\\{u+v-1,0\\} \\leq C[u,v]\\leq \\min\\{u,v\\}.\n\\tag{3.17}\\]\n\n\n\n\n\n\n\n\nNote3.9 Archimedean copulas\n\n\n\nLet \\(\\psi:[0,1]\\to[0,\\infty]\\) is a continuous, strictly decreasing, convex function with \\(\\psi(1)=0\\). The corresponding Archimedean copula is \\[\nC[u,v]=\\psi^{[-1]}\\bigl( \\psi(u)+\\psi(v)\\bigr),\n\\tag{3.18}\\] where \\[\n\\psi^{[-1]}(x)=\\begin{cases}\n\\psi^{-1}(x), & \\text{if } 0\\leq x\\leq \\psi(0),\\\\\n0, & \\text{if } \\psi(0)&lt;x\\leq \\infty.\n\\end{cases}\n\\] In particular, if \\(\\psi(0)=\\infty\\) (i.e. \\(\\lim\\limits_{t\\to0-}\\psi(t)=\\infty\\)), then \\(\\psi^{[-1]}(x)=\\psi^{-1}(x)\\) for all \\(x\\).\n\n\n\n\n\n\n\n\nWarning3.10 Example: Gumbel copula\n\n\n\nFor \\(\\alpha\\geq1\\), we consider \\[\n\\psi(t)=\\bigl( - \\ln t \\bigr)^\\alpha.\n\\tag{3.19}\\] Then \\[\nC[u,v]=\\exp \\biggl( -\\Bigl( (-\\ln u)^ \\alpha + (-\\ln v)^\\alpha\\Bigr)^{\\frac1\\alpha}\\biggr).\n\\tag{3.20}\\] Note that, for \\(\\alpha=1\\), this becomes the independence copula.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Copulas</span>"
    ]
  },
  {
    "objectID": "Ch-04.html",
    "href": "Ch-04.html",
    "title": "4  Reinsurance",
    "section": "",
    "text": "Note4.1 Notations\n\n\n\n\n\\(X\\) is the gross claim amount random variable\n\\(Y\\) is the net claim amount (paid by the main insurer after receiving the reinsurance recovery)\n\\(Z\\) is the amount paid by the reinsurer\n\n\n\n\n\n\n\n\n\nWarning4.2 Example: Excess of loss reinsurance\n\n\n\nThe insurer pays in full up to an amount \\(M\\), the reinsurer pays all above \\(M\\), if needed: \\[\nY=\\begin{cases}\nX, & \\text{if } X\\leq M,\\\\\nM, & \\text{if } X&gt;M;\n\\end{cases} \\qquad Z=X-Y.\n\\tag{4.1}\\] Then \\[\nm_{k,Y} = \\int_0^M x^k f_X(x)\\,dx + M^k \\mathbb{P}(X&gt;M),\n\\tag{4.2}\\]\n\\[\nM_Y(t)= \\int_0^M e^{tx}f_X(x)\\,dx +e^{tM}\\mathbb{P}(X&gt;M),\n\\tag{4.3}\\] and \\[\nm_{k,Z} = \\int_M^\\infty (x-M)^k f_X(x)\\,dx,\n\\tag{4.4}\\]\n\\[\nM_Z(t) = \\mathbb{P}(X\\leq M) +\\int_M^\\infty e^{t(x-M)}f_X(x)\\,dx.\n\\tag{4.5}\\]\n\n\n\n\n\n\n\n\nNote4.3 Reinsurer’s view\n\n\n\nIn the conditions of the previous example, the reinsurer pays \\(Z\\), evidently, only if \\(Z=X-Y&gt;0\\), otherwise, the reinsurer even does not know that a claim happened.\nHence, the distribution function for reinsurer is \\[\n\\begin{aligned}\nF_Z(z)&=\\mathbb{P}(Z\\leq z\\mid Z&gt;0)=\\mathbb{P}(X\\leq z+M\\mid X&gt;M)\\\\\n&= \\frac{\\mathbb{P}(M&lt;X\\leq z+M)}{\\mathbb{P}(X&gt;M)}= \\frac{F_X(z+M)-F_X(M)}{1-F_X(M)},\n\\end{aligned}\n\\] that looks familiar (see formula (1.1)). Then \\[\nf_Z(z)= \\frac{f_X(z+M)}{1-F_X(M)}, \\quad z&gt;0.\n\\]\n\n\n\n\n\n\n\n\nWarning4.4 Example: Proportional reinsurance\n\n\n\nFor \\(0&lt;\\alpha&lt;1\\), we set \\[\nY=\\alpha X, \\qquad Z=(1-\\alpha)X.\n\\tag{4.6}\\] Then e.g. \\[\n\\begin{alignat*}{2}\n\\mathbb{E}(Y)&=\\alpha\\mathbb{E}(X), &\\qquad\n\\mathbb{E}(Z)&=(1-\\alpha)\\mathbb{E}(X),\\\\\n\\mathrm{Var}(Y)&=\\alpha^2\\mathrm{Var}(X), &\\qquad\n\\mathrm{Var}(Z)&=(1-\\alpha)^2\\mathrm{Var}(X).\n\\end{alignat*}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reinsurance</span>"
    ]
  },
  {
    "objectID": "Ch-05.html",
    "href": "Ch-05.html",
    "title": "5  Compound distributions",
    "section": "",
    "text": "Theorem 5.1 (Line) The equation of any straight line, called a linear equation, can be written as:\n\\[\ny = mx + b\n\\tag{5.1}\\]\n\nSee Theorem 5.1.\n\nDefinition 5.1 (Line) The equation of any straight line, called a linear equation, can be written as:\n\\[\ny = mx + b\n\\tag{5.2}\\]\n\nSee Definition 5.1.\n\n\n\n\n\n\nNote5.1 The collective risk model\n\n\n\nThe number \\(N\\) of claims (raised during an interval of time) is, usually, random, i.e. we may treat it as a random variable \\[\nN:\\Omega\\to\\mathbb{Z}_+:=\\mathbb{N}\\cup\\{0\\}.\n\\]\nAssume that all claims, \\(X_1\\), , \\(X_N\\) are i.i.d.r.v. (independent identically distributed random variables).\nThe total sum of all claims is then \\[\nS=S_N:=X_1+\\ldots+X_N,\n\\tag{5.3}\\] where \\(S:=0\\) if \\(N=0\\).\nThen \\[\nF_S(x)=\\sum_{n=0}^\\infty \\mathbb{P}(N=n)\\, \\mathbb{P}(S\\leq x \\mid N=n).\n\\tag{5.4}\\]\nNext, \\[\n\\mathbb{E}(S) = \\mathbb{E}(N)\\, \\mathbb{E}(X);\n\\tag{5.5}\\]\n\\[\n\\mathrm{Var}(S) = \\mathbb{E}(N)\\, \\mathrm{Var}(X) + \\mathrm{Var}(N)\\, \\left( \\mathbb{E}(X) \\right)^2;\n\\tag{5.6}\\]\n\\[\nM_S(t) = M_N\\left( \\ln M_X(t) \\right).\n\\tag{5.7}\\]\n\n\n\n\n\n\n\n\nNote5.2 The Poisson distribution (reminder)\n\n\n\nRecall that \\(N:\\Omega\\to\\mathbb{Z}_+\\) has the Poisson distribution with parameter \\(\\lambda&gt;0\\), notation: \\(N\\sim Po(\\lambda)\\), if \\[\n\\mathbb{P}(N=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda}, \\qquad n\\in\\mathbb{Z}_+.\n\\tag{5.8}\\]\nThen \\[\n\\mathbb{E}(N)=\\mathrm{Var}(N)=\\lambda,\n\\tag{5.9}\\]\n\\[\nM_N(t)= \\exp\\bigl( \\lambda(e^t-1) \\bigr).\n\\tag{5.10}\\]\n\n\n\n\n\n\n\n\nNote5.3 The compound Poisson distribution\n\n\n\nLet \\(N\\sim Po(\\lambda)\\), let \\(X_1, \\ldots, X_N\\) are i.i.d.r.v., let \\(m_k:=m_{k,X}\\). Then \\(S=X_1+\\ldots+X_N\\) has the compound Poisson distribution with the parameter \\(\\lambda\\) and \\[\n\\mathbb{E}(S)=\\lambda m_1,\n\\tag{5.11}\\]\n\\[\n\\mathrm{Var}(S)=\\lambda m_2,\n\\tag{5.12}\\]\n\\[\nM_S(t)= \\exp\\bigl( \\lambda (M_X(t)-1) \\bigr).\n\\tag{5.13}\\]\n\n\n\n\n\n\n\n\nNote5.4 Sums of independent compound Poisson r.v.\n\n\n\nLet \\(S_1,\\ldots, S_m\\) be independent compound Poisson random variables with parameters \\(\\lambda_i\\) and CDF of the single claims \\(F_i(x)\\), \\(1\\leq i\\leq m\\), i.e. \\[\nS_i = X_1^{(i)}+\\ldots+X_{N_i}^{(i)},\n\\] where, for each \\(i\\), \\(\\{X_j^{(i)}\\}\\) are i.i.d.r.v. with CDF \\(F_i\\), and \\(N_i\\sim Po(\\lambda_i)\\). Moreover, \\(\\{X_j^{(i)}\\}\\) are also independent for different \\(i\\). Then \\[\n\\mathbf{S}:=S_1+\\ldots+S_m\n\\] is a compound Poisson random variable with the parameter \\[\n\\Lambda=\\lambda_1+\\ldots+\\lambda_m\n\\tag{5.14}\\] and the CDF of the single claim \\[\nF(x)=\\frac{1}{\\Lambda} \\bigl( \\lambda_1 F_1(x)+\\ldots+\\lambda_m F_m(x) \\bigr),\n\\tag{5.15}\\] i.e. \\[\nS=Y_1+\\ldots+Y_N\n\\] for i.i.d.r.v. \\(\\{Y_j\\}\\) with the CDF \\(F(x)\\), and \\(N\\sim Po(\\Lambda)\\).\n\n\n\n\n\n\n\n\nNote5.5 The compound binomial distribution\n\n\n\n\\(N\\sim Bin(n,p)\\), \\(n\\in\\mathbb{N}\\), \\(p\\in[0,1]\\), iff, for \\(0\\leq k\\leq n\\), \\[\n\\mathbb{P}(N=k)=\\binom{n}{k} p^k(1-p)^{n-k}.\n\\tag{5.16}\\] Then \\[\n\\begin{gathered}\n\\mathbb{E}(N) = np, \\qquad \\mathrm{Var}(N)=np(1-p), \\\\ M_N(t)=(pe^t+1-p)^n.\n\\end{gathered}\n\\tag{5.17}\\] We can define \\(S=X_1+\\ldots+X_N\\) for i.i.d.r.v. \\(X_i\\), and the distribution of \\(S\\) is called the compound binomial distribution. Then \\[\n\\mathbb{E}(S)=np m_{1,X}, \\quad \\mathrm{Var}(S)= np m_{2,X} -np^2 m_{1,X}^2,\n\\]\n\\[\nM_S(t) = (pM_X(t)+1-p)^n.\n\\tag{5.18}\\]\n\n\n\n\n\n\n\n\nNote5.6 Agrregated claims with reinsurance\n\n\n\n\nThe aggregated claim \\(S=X_1+\\ldots+X_N\\) of a collective risk model can be done when the reinsurance is in force.\nConsider the case when the reinsurance is applied to each individual claim.\nLet \\(Y_i\\) be the amount paid by the main insurer for the claim \\(X_i\\), and \\(Z_i\\) be the claim paid by the reinsurer, so \\(X_i=Y_i+Z_i\\).\nLet \\(S_I=Y_1+\\ldots+Y_N\\) be the aggregated claim amount paid by the insurer, and \\(S_R=Z_1+\\ldots+Z_N\\) be the aggregated claim amount paid by the reinsurer.\nOf course, formulas (5.7) are still true if we replace there \\(S,X\\) by \\(S_I,Y\\) or by \\(S_R,Z\\), respectively.\nNote that, for the individual excess of loss reinsurance, the reinsurer pays \\(Z_i\\) only if \\(Z_i=X_i-M&gt;0\\). We can introduce \\(J_i=1\\) if \\(X_i&gt;M\\) and \\(J_i=0\\) otherwise. Then \\[\nN_R:=J_1+\\ldots+J_N\n\\] is the number of claims paid by the reinsurer.\n\\(X_1,\\ldots,X_N\\) are i.i.d.r.v., let \\[\n\\mathbb{P}(J_i=1)=\\mathbb{P}(X_i&gt;M)=:\\rho.\n\\] Then (actually \\(J_i\\sim Bin(1,\\rho)\\)) \\[\nM_{J_i}(t)=\\mathbb{E}(e^{t J_i})= \\rho e^t +(1-p)e^0 = \\rho e^t +1-p,\n\\] and for the compound random variable \\(N_R\\), \\[\nM_{N_R}(t)=M_N\\bigl(\\ln (\\rho e^t +1-p)\\bigr).\n\\tag{5.19}\\]\nLet \\(\\{i_1,\\ldots,i_{N_R}\\}\\subset\\{1,\\ldots, N\\}\\) be indexes such that \\(X_{i_k}&gt;M\\) for \\(1\\leq k\\leq N_R\\), and set \\(W_k:=X_{i_k}-M\\). Then there is another representation \\[\nS_R = W_1+\\ldots + W_{N_R}.\n\\tag{5.20}\\]\nIf, additionally, \\(N\\sim Po(\\lambda)\\) for a \\(\\lambda&gt;0\\), then (5.19) reads, by (5.10) or (5.13), \\[\nM_{N_R}(t) =\\exp\\Bigl(\\lambda \\bigl(M_{J_i}(t)-1\\bigr)\\Bigr) =\\exp\\bigl(\\rho\\lambda (e^t-1)\\bigr),\n\\] i.e. \\(N_R\\sim Po(\\rho\\lambda)\\), by (5.10). (That is nothing but the thinning property of the Poisson distribution.)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Compound distributions</span>"
    ]
  },
  {
    "objectID": "Ch-06.html",
    "href": "Ch-06.html",
    "title": "6  Time series",
    "section": "",
    "text": "Note10.1 Stochastic processes\n\n\n\n\nLet \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) be a probability space and \\((S,\\mathcal{S})\\) be a measurable state space.\nLet \\(J\\) be a set, whose points are usually interpreted as moments of time, i.e. \\(J\\subset\\mathbb{R}_+:=[0,\\infty)\\).\nA stochastic process (a.k.a. random process) is a collection of \\(S\\)-valued random variables parametrized by \\(t\\in J\\): \\[\n\\{X(t): \\Omega\\to S \\mid t\\in J\\}.\n\\]\nWe have hence \\(X(t)=X(t,\\omega)\\), \\(t\\in J\\), \\(\\omega\\in\\Omega\\), i.e. one can think about a stochastic process as a function of two variables.\nWe will normally omit \\(\\omega\\) and write \\(t\\) as a subscript: \\[\nX_t:=X(t)=X(t,\\omega).\n\\]\nIf \\(J\\) is continuous set, e.g. \\(J=\\mathbb{R}_+=[0,\\infty)\\), then \\(\\{X_t\\mid t\\in J\\}\\) is called a continuous time stochastic process.\nIf \\(J\\) is a discrete set, e.g. \\(J=\\mathbb{Z}_+=\\{0,1,2,\\ldots\\}\\), then \\(\\{X_t\\mid t\\in J\\}\\) is called a discrete time stochastic process.\n\nIn this case, we will sometimes write \\(n\\) instead of \\(t\\).\n\n\n\n\n\n\n\n\nCaution10.2 Definition: Sample path\n\n\n\nRecall that a stochastic process is a function of two variables, \\(t\\) and \\(\\omega\\). If we fix an \\(\\omega\\in\\Omega\\), the set \\(\\{X_t(\\omega)=X(t,\\omega) \\mid t\\in J\\}\\) is called a sample path of the process (for the chosen \\(\\omega\\)).\n\n\n\n\n\n\n\n\nCaution10.3 Definition: Time series process\n\n\n\nTime series is the sample path of a discrete time stochastic process.\nOften, however, this term is used for the stochastic process itself.\nAnother term, which you may find in the literature, is time series process.\nWe will deal with real-valued time series, i.e. \\(3{S\\subset\\mathbb{R}}\\).\nWe may also assume that \\(J\\subset\\mathbb{Z}\\).\n\n\n\n\n\n\n\n\nCaution10.4 Definition: Strictly stationary process\n\n\n\nA time series process \\(\\{X_t\\}\\) is called if, for all \\(n\\in\\mathbb{N}\\) and for all \\(k,t_1,\\ldots,t_n \\in J\\) such that \\(t_1+k,\\ldots,t_n+k\\in J\\), the joint distributions of random variables \\(X_{t_1},\\ldots, X_{t_n}\\) and \\(X_{t_1+k},\\ldots, X_{t_n+k}\\) are identical.\nIn other words, for all \\(\\Delta_1,\\ldots,\\Delta_n\\in\\mathcal{S}\\), \\[\n\\mathbb{P}\\bigl(  X_{t_1+k}\\in \\Delta_1, \\ldots, X_{t_n+k}\\in \\Delta_n\\bigr)\n\\tag{6.1}\\] does not depend on \\(k\\).\n\n\n\n\n\n\n\n\nTip10.5 Remark\n\n\n\nStress that, normally, the (random) values of \\(X_t\\) at different moments of time \\(t\\) are not independent, hence, the probability in (6.1) is not the product of the corresponding probabilities \\(\\mathbb{P}(  X_{t_i+k}\\in \\Delta_i)\\).\n\n\n\n\n\n\n\n\nCaution10.6 Definition: Weakly stationary process\n\n\n\nA time series process \\(\\{X_t\\}\\) is called , if the following conditions hold:\n\n\\(\\mathbb{E}(X_t)\\) does not depend on \\(t\\in J\\) (i.e. it is a constant in \\(t\\));\n\\(\\mathbb{E}(X_t^2)&lt;\\infty\\) for each \\(t\\in J\\);\nFor each \\(s\\in J\\), \\[\n\\begin{aligned}\n\\mathrm{cov}(X_t,X_{t+s}):&=\\mathbb{E}\\bigl((X_t-\\mathbb{E}(X_t))(X_s-\\mathbb{E}(X_s))\\bigr)\\notag\\\\\n& = \\mathbb{E}(X_t\\, X_{t+s})-\\mathbb{E}(X_t)\\,\\mathbb{E}(X_{t+s})\n\\end{aligned}\n\\] does not depend on \\(t\\in J\\) (assuming that \\(t+s\\in J\\)).\n\nEquivalently, \\(\\mathrm{cov}(X_t,X_s)\\) depends on the lag \\(s-t\\) only (for \\(s&gt;t\\)).\nIn particular, \\(\\mathrm{Var}(X_t)=\\mathrm{cov}(X_t,X_t)\\) does not depend on \\(t\\) (here \\(s=0\\)).\n\n\n\n\n\n\n\n\nTip10.7 Remark\n\n\n\nLet \\(\\{X_t\\}\\) be a strictly stationary stochastic process and \\(\\mathbb{E}(X_t^2)&lt;\\infty\\). Then \\(\\{X_t\\}\\) is weakly stationary.\n\n\n\n\n\n\n\n\nNote10.8 Autocovariance and autocorrelation functions\n\n\n\nFor a (weakly) stationary time series,\nthe function \\[\n\\gamma_s:=\\mathrm{cov}(X_t,X_{t+s}), \\qquad s\\in J,\n\\] is called the autocovariance function.\nFor a (weakly) stationary time series, the autocorrelation function is \\[\n\\begin{aligned}\n\\rho_s:&=\\corr(X_t,X_{t+s})\\notag\\\\&=\\frac{\\mathrm{cov}(X_t,X_{t+s})}{\\sqrt{\\mathrm{Var}(X_t)}\\sqrt{\\mathrm{Var}(X_{t+s})}}=\\frac{\\gamma_s}{\\gamma_0}.\n\\end{aligned}\n\\]\nLet \\(J=\\mathbb{Z}\\). Then the autocovariance and autocorrelation functions are even functions.\n\n\n\n\n\n\n\n\nWarning10.9 Example\n\n\n\nLet \\(Y\\) and \\(Z\\) be two uncorrelated identically distributed random variables with zero mean and variance \\(\\sigma^2\\); i.e. \\(\\mathrm{cov}(Y,Z)=0\\), \\(\\mathbb{E}(Y)=\\mathbb{E}(Z)=0\\), \\(\\mathrm{Var}(Y)=\\mathrm{Var}(Z)=\\sigma^2\\).\nLet \\(\\lambda\\in[0,2\\pi]\\) be a fixed number, and consider a continuous-time random process \\[\nX_t = Y \\cos(\\lambda t) + Z\\sin (\\lambda t), \\quad t\\in\\mathbb{R}_+.\n\\] Then (check!) \\[\nE(X_t)=0, \\quad E(X_t^2)=\\sigma^2&lt;\\infty,\n\\]\n\\[\n\\begin{aligned}\n&\\quad \\mathrm{cov}(X_t,X_{t+s}) =\n\\mathbb{E}(X_tX_{t+s}) \\\\\n&= \\mathbb{E}\\bigl(Y^2\\cos(\\lambda t)\\cos(\\lambda (t+s))\n+Z^2\\sin(\\lambda t)\\sin(\\lambda (t+s))\\bigr)\n\\\\&=\\sigma^2 \\cos(\\lambda s)=:\\gamma_s,\n\\end{aligned}\n\\] hence \\(\\{X_t\\}\\) is weakly stationary, and \\(\\rho_s=\\cos(\\lambda s)\\).\n\n\n\n\n\n\n\n\nCaution10.10 Definition: White noise\n\n\n\nA time series process \\(\\{e_t\\}\\) is called a white noise iff \\[\n\\mathbb{E}(e_t)=0, \\qquad \\mathrm{cov}(e_t,e_{t+s})=\\begin{cases}\n\\sigma^2, & \\text{if } s=0,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\] In other words, the white noise is an example of a weakly stationary time series of uncorrelated random variables with zero mean.\n\n\n\n\n\n\n\n\nNote10.11 Backward shift and difference operators\n\n\n\nLet \\(X=\\{X_t\\}\\) be a time series process.\n\nThe backward shift operator \\(B\\) is given by \\[\n(BX)_t = X_{t-1}.\n\\]\nThe difference operator \\(\\nabla:=1\\!\\!1-B\\) is given by \\[\n(\\nabla X)_t = X_t-X_{t-1}.\n\\]\nBoth operators can be applied repeatedly, e.g. \\[\n\\begin{aligned}\n(B^2X)_t &= (BX)_{t-1}= X_{t-2},\\\\\n(\\nabla^2 X)_t & =X_t-2X_{t-1}+X_{t-2},\\\\\n(B\\nabla X)_t & =X_{t-1}-X_{t-2}=(\\nabla B X)_t.\n\\end{aligned}\n\\]\nThis shows that \\(B\\) and \\(\\nabla\\) commute, that is clear also from \\(\\nabla=1\\!\\!1-B\\).\nThe latter formula allows to simplify calculations (henceforce, we will omit brackets: e.g. \\(\\nabla X_t\\) instead of \\((\\nabla X)_t\\), unless it may lead to misunderstanding): \\[\n\\begin{aligned}\n\\nabla^3 X_t & = (1\\!\\!1-B)^3 X_t \\\\& = (1\\!\\!1-3B+3B^2-B^3)X_t \\\\\n& = X_t -3X_{t-1}+3X_{t-2}-X_{t-3}.\n\\end{aligned}\n\\]\nWe can also rewrite expressions using difference operators, e.g.  \\[\n\\begin{aligned}\n&\\quad X_t-5X_{t-1}+7X_{t-2}-3X_{t-3}\\\\\n&=X_t-X_{t-1}-4X_{t-1}+4X_{t-2}+3X_{t-2}-3X_{t-3}\\\\\n&=\\nabla X_t -4\\nabla X_{t-1}+3\\nabla X_{t-2}\\\\\n& =\\nabla X_t-\\nabla X_{t-1}-3\\nabla X_{t-1}+3\\nabla X_{t-2}\\\\\n& = \\nabla^2 X_t -3\\nabla^2 X_{t-1}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nWarning10.12 Example: Inversion relation\n\n\n\nLet \\(Y_t=\\nabla X_t=X_t-X_{t-1}\\), \\(t\\in \\mathbb{N}\\). Then \\[\n\\begin{aligned}\nX_t&= Y_t+X_{t-1}= Y_t+Y_{t-1}+X_{t-2}=\\ldots\\\\\n&=X_0 +Y_t+Y_{t-1}+Y_{t-2}+\\ldots +Y_1\\\\\n& =X_0 +Y_t+BY_t+B^2Y_t + \\ldots +B^{t-1}Y_t\\\\\n& = X_0+(1\\!\\!1+B+B^2+\\ldots B^{t-1})Y_t,\n\\end{aligned}\n\\] where \\(1\\!\\!1 =B^0\\) is the identity operator.\nNote that the last brackets contain \\(t\\) summands.\n\n\n\n\n\n\n\n\nNote10.13 The autoregressive process, \\(AR(p)\\)\n\n\n\n\nLet \\(p\\in\\mathbb{N}\\). The autoregressive process \\(AR(p)\\) of the order \\(p\\) is: \\[\nX_t = \\mu + \\alpha_1 (X_{t-1}-\\mu)+\n\\ldots +\n\\alpha_p (X_{t-p}-\\mu) + e_t,\n\\tag{6.2}\\] where \\(\\mu\\in\\mathbb{R}\\) and \\(e_t\\) is a white noise.\nThe relation (6.2) can be rewritten as follows: \\[\n\\bigl( 1\\!\\!1 - \\alpha_1 B - \\ldots -\\alpha_p B^p\\bigr)(X_t-\\mu)=e_t.\n\\tag{6.3}\\]\nIn particular, we will be interested to find the conditions when \\(X_t\\) is weakly stationary.\nNote that \\(AR(1)\\) is the only autoregressive process which is a Markov chain.\n\nWe consider this case first, in more details.\n\n\n\n\n\n\n\n\nNote10.14 The first-order autoregressive process, \\(AR(1)\\)\n\n\n\nLet in (6.2) \\(p=1\\) and \\(\\alpha:=\\alpha_1{{\\neq 0}}\\).\nThen, iterating, \\[\n\\begin{aligned}\nX_t-\\mu&=\\alpha(X_{t-1}-\\mu)+e_t\\\\\n&= \\alpha^t (X_0-\\mu)+\\sum_{k=0}^{t-1}\\alpha^ke_{t-k}.\n\\end{aligned}\n\\tag{6.4}\\] Then, since \\(\\mathbb{E}(e_t)=0\\) for all \\(t\\),\n\\[\n\\mathbb{E}(X_t)=\\mu+\\alpha^t (\\mathbb{E}(X_0)-\\mu).\n\\] Therefore, to have \\(\\mathbb{E}(X_t)\\) independent on \\(t\\), we would require \\({\\mathbb{E}(X_0)=\\mu}\\).\nNext, assuming that \\(X_0\\) and \\(e_t\\) are independent for all \\(t\\),\nwe get, denoting \\(\\sigma^2:=\\mathrm{Var}(e_t)\\),\n\\[\n\\begin{aligned}\n\\mathrm{Var}(X_t) &=\\alpha^{2t}\\mathrm{Var}(X_0)+\\sum_{k=0}^{t-1}\\alpha^{2k}\\sigma^2\\\\\n& = \\alpha^{2t}\\mathrm{Var}(X_0) + \\sigma^2 \\frac{1-\\alpha^{2t}}{1-\\alpha^2}\\\\\n& = \\frac{\\sigma^2}{1-\\alpha^2}+\\alpha^{2t}\\biggl(\\mathrm{Var}(X_0)-\\frac{\\sigma^2}{1-\\alpha^2}\\biggr),\n\\end{aligned}\n\\] provided that \\(|\\alpha|\\neq 1\\).\nTherefore, to have \\(\\mathrm{Var}(X_t)\\) independent on \\(t\\), we would require \\({\\mathrm{Var}(X_0)=\\frac{\\sigma^2}{1-\\alpha^2}}\\) and \\(|\\alpha|\\neq1\\).\n(Note that \\(|\\alpha|=1\\) implies \\(\\mathrm{Var}(X_t)=\\mathrm{Var}(X_0)+\\sigma^2 t\\).)\nHowever, the restrictions on \\(X_0\\) are often not natural.\nMore importantly, on practice, people study processes which describe some established characteristics, which started to change a while ago, i.e., informally, the starting time was at “\\(t=-\\infty\\)”.\nMore rigorously, we assume \\(t\\in\\mathbb{Z}\\) in (6.4) and continue the iteration there (i.e. rewrite \\(X_0\\) through \\(X_{-1}\\) and so on).\nWe will get then: \\[\nX_t-\\mu=\\sum_{k=0}^\\infty \\alpha^k e_{t-k}.\n\\tag{6.5}\\]\nTherefore, if \\({|\\alpha|&lt;1}\\), then \\[\n\\mathbb{E}(X_t)=\\mu, \\qquad \\mathrm{Var}(X_t) = \\frac{\\sigma^2}{1-\\alpha^2}.\n\\] Moreover, we have then \\[\n\\begin{aligned}\n\\mathrm{cov}(X_t,X_{t+s})& = \\sum_{k=0}^\\infty\\sum_{j=0}^\\infty \\alpha^k \\alpha^j\\mathrm{cov}(e_{t-k} , e_{t+s-j})\\\\\n&= \\sum_{k=0}^\\infty\\alpha^k \\alpha^{k+s} \\sigma^2 =\\alpha^s \\frac{\\sigma^2}{1-\\alpha^2}.\n\\end{aligned}\n\\] Hence, indeed, \\(X_t\\) is a weakly stationary process with the autocovariance function \\(\\gamma_s=\\gamma_0 \\alpha^s\\),\nand thus the autocorrelation function \\(\\rho_s=\\alpha^s\\).\n\n\n\n\n\n\n\n\nNote10.15 Inverse operator to \\(1-\\alpha B\\)\n\n\n\nThe relation (6.4) can be rewritten, see (6.3): \\[\n(1\\!\\!1-\\alpha B)(X_t-\\mu)=e_t.\n\\tag{6.6}\\]\nNext, its solution (6.5) can be also rewritten in terms of \\(B\\): \\[\nX_t-\\mu = \\sum_{k=0}^\\infty \\alpha^k B^ke_t.\n\\] In other words, for \\({|\\alpha|&lt;1}\\), there exists the inverse operator to \\(1-\\alpha B\\): \\[\n(1\\!\\!1-\\alpha B)^{-1}=\\sum_{k=0}^\\infty \\alpha^k B^k.\n\\]\n\n\n\n\n\n\n\n\nNote10.16 The characteristic equation for \\(AR(1)\\)\n\n\n\nThe characteristic equation for \\(AR(1)\\) (6.4) is \\[\n1-\\alpha z=0.\n\\tag{6.7}\\] Therefore (assuming that \\(\\alpha\\neq0\\)), \\({|\\alpha|&lt; 1}\\) iff the only root of the characteristic equation (6.7) \\(z=\\dfrac1{\\alpha}\\) is such that \\({|z|&gt;1}\\).\n\n\n\n\n\n\n\n\nNote10.17 The characteristic equation for \\(AR(p)\\)\n\n\n\nConsider now a general \\(p\\in\\mathbb{N}\\) and \\(AR(p)\\) process given by (6.2).\nSimilarly to \\(AR(1)\\) case, we can, looking at its rewriting (6.3), construct the characteristic equation of \\(AR(p)\\): \\[\n1\\!\\!1 - \\alpha_1 z -\\alpha_2 z^2 - \\ldots -\\alpha_p z^p=0.\n\\tag{6.8}\\]\n\n\n\n\n\n\n\n\nImportant10.18 Theorem: Weakly stationary \\(AR(p)\\) process\n\n\n\nLet all the roots of the characteristic equation (6.8) (including complex roots) lie outside the unit circle on the complex plain,\ni.e. let \\(|z_k|&gt;1\\) for all roots \\(z_1,\\ldots,z_p\\) of (6.8).\nThen \\(AR(p)\\) process (6.2) is weekly stationary.\nThe opposite is also true.\n\n\nExample: \\(AR(1)\\), \\(\\alpha_1=\\alpha\\), \\(z_1=\\frac{1}{\\alpha}\\)\n\n\n\nStationary vs. Nonstationary behaviour\n\n\n\n\n\n\n\n\nNote10.19 The moving average process, \\(MA(q)\\)\n\n\n\n\nLet \\(q\\in\\mathbb{N}\\). The moving average process, \\(MA(q)\\) of the order \\(q\\) is: \\[\nX_t=\\mu+e_t+\\beta_1 e_{t-1}+\\ldots +\\beta_q e_{t-q},\n\\tag{6.9}\\] where \\(\\mu\\in\\mathbb{R}\\) and \\(e_t\\) is the white noise.\nIt can be rewritten: \\[\nX_t-\\mu =\\bigl( 1\\!\\!1+\\beta_1 B+\\beta_2 B^2 +\\ldots+\\beta_q B^q \\bigr)e_t.\n\\tag{6.10}\\]\nClearly, since \\(\\mathbb{E}(e_t)=\\) and \\(\\mathrm{Var}(e_t)=\\sigma^2\\), we have \\[\n\\mathbb{E}(X_t)=\\mu, \\qquad \\mathrm{Var}(X_t)=\\sigma^2\\biggl(1+\\sum_{k=1}^q \\beta_k^2\\biggr).\n\\]\nMoreover, setting \\(\\beta_0:=1\\), we have \\[\n\\begin{aligned}\n\\mathrm{cov}(X_t,X_{t+s})&=\\mathbb{E}(X_t\\, X_{t+s})\\\\&= \\sum_{k=0}^q\\sum_{j=0}^q \\beta_k\\beta_j \\mathrm{cov}(e_{t-k},e_{t+s-j})\\\\\n& = \\sum_{k=0}^{q-s}\\beta_k\\beta_{k+s} \\sigma^2.\n\\end{aligned}\n\\] In particular, any \\(MA(q)\\) process is weakly stationary.\n\n\n\n\n\n\n\n\n\nCaution10.20 Definition: Invertible \\(MA(q)\\) process\n\n\n\nAn \\(MA(q)\\) process (6.9) is called invertible,\nif the noise at time \\(t\\) can be represented through the values of the process at times \\(s\\leq t\\):\n\\[\ne_t =\\mathrm{const}+ X_t  +\\gamma_1 X_{t-1}+\\ldots+\\gamma_q X_{t-q}+\\ldots,\n\\tag{6.11}\\] for some \\(\\gamma_k\\in\\mathbb{R}\\), such that {\\(\\sum\\limits_{k=1}^\\infty\\gamma_k^2&lt;\\infty\\)}.\nIn other words \\(MA(q)\\) process is invertible if the operator $1!!1+_1 B ++_q B^q $ in (6.10) is invertible.\n\n\n\n\n\n\n\n\nImportant10.21 Theorem: Invertible \\(MA(q)\\) process\n\n\n\nLet \\(MA(q)\\) process (6.9) be given. Consider its characteristic equation \\[\n1+\\beta_1z+\\beta_2 z^2+\\ldots+\\beta_q z^q=0.\n\\tag{6.12}\\]\nLet all the roots of this characteristic equation (including complex roots) lie outside the unit circle on the complex plain, i.e. let \\(|z_k|&gt;1\\) for all roots \\(z_1,\\ldots,z_q\\) of (6.12).\nThen \\(MA(q)\\) process (6.9) is invertible.\nThe opposite statement is also true.\n\n\n\n\n\n\n\n\nTip10.22 Remark\n\n\n\nNote that \\(AR(p)\\) process is always invertible in this sense, by the very definition (6.2).\n\n\n\n\n\n\n\n\nNote10.23 Invertible \\(MA(1)\\) process\n\n\n\nFor \\(q=1\\), the proof of the previous theorem becomes especially simple.\nNamely, then (denoting \\(\\beta:=\\beta_1\\)) \\[\n\\begin{aligned}\ne_t&=X_t-\\mu - \\beta e_{t-1}\\\\&=X_t-\\mu - \\beta (X_{t-1}-\\mu - \\beta e_{t-2})=\\ldots\n\\\\&= (X_t-\\mu) -\\beta (X_{t-1}-\\mu)\\\\&\\quad +\\beta^2 (X_{t-2}-\\mu)-\\beta^3(X_{t-3}-\\mu)+\\ldots\n\\\\&=c+\\sum_{k=0}^\\infty (-\\beta)^k X_{t-k},\n\\end{aligned}\n\\] where, {for \\(|\\beta|&lt;1\\) only}, \\[\nc= -\\mu\\sum_{k=0}^\\infty (-\\beta)^k=-\\frac{\\mu}{1+\\beta}.\n\\] Let \\(\\gamma_k:=(-\\beta)^k\\) with \\(|\\beta|&lt;1\\), then we get\n\\[\n\\sum\\limits_{k=1}^\\infty \\gamma_k^2=\\frac{1}{1-\\beta^2}&lt;\\infty.\n\\]\nActually, we have shown that, for \\(|\\beta|&lt;1\\), \\[\n(1\\!\\!1+\\beta B)^{-1} = 1\\!\\!1-\\beta B+\\beta^2 B^2-\\beta^3 B^3+\\ldots.\n\\] The characteristic equation is then \\(1+\\beta z=0\\) and its the only root is \\(z=-\\frac{1}{\\beta}\\), thus, \\(|z|&gt;1\\) iff \\(|\\beta|&lt;1\\).\n\n\n\n\n\n\n\n\nNote10.24 The autoregressive moving average process, \\(ARMA(p,q)\\)\n\n\n\nWe consider now a natural combination of \\(AR(p)\\) and \\(MA(q)\\).\nLet \\[\n\\begin{aligned}\nX_t-\\mu& = \\alpha_1 (X_{t-1}-\\mu)+\\ldots +\\alpha_p (X_{t-p}-\\mu) \\notag\n\\\\&\\quad+ e_t+\\beta_1 e_{t-1}+\\ldots +\\beta_q e_{t-q}.\n\\end{aligned}\n\\] Or, it can be rewritten: \\[\n\\begin{multlined}\n(1\\!\\!1-\\alpha_1 B - \\ldots -\\alpha_p B^p)(X_t-\\mu)\\\\=\n(1\\!\\!1+\\beta_1 B+\\ldots+\\beta_q B^q)e_t.\n\\end{multlined}\n\\tag{6.13}\\]\n\n\n\n\n\n\n\n\nImportant10.25 Theorem\n\n\n\nAn \\(ARMA(p,q)\\) process if weakly stationary iff its \\(AR(p)\\) is weakly stationary, i.e. iff all the roots of \\[\n1 - \\alpha_1 z -\\alpha_2 z^2 - \\ldots -\\alpha_p z^p=0\n\\] lie outside the unit circle on the complex plane.\nAn \\(ARMA(p,q)\\) process is invertible (i.e. there exists an expansion (6.11)) iff its \\(MA(q)\\) is invertible, i.e. iff all the roots of \\[\n1+\\beta_1z+\\beta_2 z^2+\\ldots+\\beta_q z^q=0\n\\] lie outside the unit circle on the complex plane.\n\n\n\n\n\n\n\n\nTip10.26 Remark\n\n\n\nThe expansion (6.5) shows that, actually, any \\(AR(1)\\) process with \\(|\\alpha|&lt;1\\) is an \\(MA(\\infty)\\) process with \\(\\beta_k=\\alpha^k\\), the latter means, by definition, an {infinite} sum in (6.9) with \\(\\sum\\limits_{k}\\beta_k^2&lt;\\infty\\).\nMoreover, it can be shown that any \\(AR(p)\\) process is an \\(MA(\\infty)\\) process in this sense.\n\n\n\n\n\n\n\n\nNote10.27 Non-stationary process: \\(ARIMA(p,j,q)\\)\n\n\n\nA process \\(X_t\\) is called an \\(ARIMA(p,j,q)\\) process if \\(X_t\\) is not weakly stationary, but \\(\\nabla^j X_t\\) is a weakly stationary \\(ARMA(p,q)\\) process.\n\n\n\n\n\n\nWarning10.28 Example\n\n\n\nLet \\(X_t=X_{t-1}+e_t\\), then \\(X_t\\) is not weakly stationary, but \\(Y_t=\\nabla X_t = e_t\\) is weakly stationary \\(ARMA(0,0)\\) process, thus \\(X_t\\) is an \\(ARIMA(0,1,0)\\) process.\n\n\nDenote \\(Y_t=\\nabla^j X_t=(1\\!\\!1-B)^j X_t\\).\nAssume, for simplicity, that \\(\\mathbb{E}(X_t)=0\\) (but \\(\\mathrm{Var}(X_t)\\) depends on \\(t\\)), then \\(\\mathbb{E}(Y_t)=0\\) and if \\(Y_t\\) is an \\(ARMA(p,q)\\), it should satisfy (6.13) with \\(\\mu=0\\).\nThen (6.13) takes the form \\[\n\\begin{multlined}\n(1\\!\\!1-\\alpha_1B-\\ldots-\\alpha_p B^p)(1\\!\\!1-B)^j X_t \\\\=(1\\!\\!1+\\beta_1 B+\\ldots +\\beta_q B^q)e_t.\n\\end{multlined}\n\\]\nTherefore, if we consider the \\(AR\\)-characteristic equation for process \\(X_t\\), it will have the form \\[\n(1 - \\alpha_1 z -\\alpha_2 z^2 - \\ldots -\\alpha_p z^p)(1-z)^j=0,\n\\] i.e. it has the root \\(1\\) of multiplicity \\(j\\). If all other roots lie outside the unit circle, \\(X_t\\) is an \\(ARIMA(p,j,q)\\) process.\n\n\n\n\n\n\n\n\nWarning10.29 Example\n\n\n\nLet \\[\nX_t=0.6X_{t-1}+0.3 X_{t-2}+0.1X_{t-3}+e_t-e_{t-1}.\n\\] The \\(AR\\)-characteristic equation is \\[\n1-0.6z-0.3z^2-0.1z^3=0.\n\\] It is easy to see that \\(z=1\\) is a root.\nUsing the long division rule, or just rewriting \\[\n\\begin{gathered}\n1-z+ 0.4z-0.4z^2+0.1z^2-0.1z^3=0, \\\\\n(1-z)(1+0.4z+0.1z^2)=0,\n\\end{gathered}\n\\] we get that \\[\nz^2+4z+10=0, \\qquad z=-2\\pm i\\sqrt{6},\n\\] and \\(|z|=\\sqrt{10}&gt;1\\).\nTherefore, \\(X_t\\) is an \\(ARIMA(2,1,1)\\) process,\ni.e. \\(\\nabla X_t\\) is a weakly stationary \\(ARMA(2,1)\\) process.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "Ch-07.html",
    "href": "Ch-07.html",
    "title": "7  Survival models",
    "section": "",
    "text": "Note6.1 Main objects of study and notations\n\n\n\n\nThe future lifetime of a newborn person is a continuous random variable \\(T:\\Omega\\to[0,\\mathfrak{w} ]\\), where $ $ is the limiting age.\nDistribution function of \\(T\\) is denoted \\[\nF(t):=\\mathbb{P}(T\\leq t), \\qquad t\\geq0.\n\\]\nSurvival function of \\(T\\) is \\[\nS(t):=\\mathbb{P}(T&gt;t)=1-F(t), \\qquad t\\geq0.\n\\]\nThe future lifetime after age \\(x\\), for \\(x\\in[0,\\mathfrak{w} ]\\), is a random variable \\(T_x:\\Omega\\to [0,\\mathfrak{w} -x]\\) (i.e. \\(T=x+T_x\\)). In particular, \\(T_0=T\\).\nDistribution function of \\(T_x\\) is denoted \\[\nF_x(t) :=\\mathbb{P}(T_x\\leq t).\n\\]\nSurvival function of \\(T_x\\) is denoted \\[\nS_x(t) :=\\mathbb{P}(T_x&gt; t)=1-F_x(t).\n\\]\nRelation between \\(F_x\\) and \\(F\\) (or \\(S\\)): \\[\n\\begin{aligned}\nF_x(t)&=\\mathbb{P}(T\\leq x+t\\mid T&gt;x)=\\frac{\\mathbb{P}(x&lt;T\\leq x+t)}{\\mathbb{P}(T&gt;x)}\\\\\n& =\\frac{F(x+t)-F(x)}{S(x)}=\\frac{F(x+t)-F(x)}{1-F(x)}.\n\\end{aligned}\n\\tag{7.1}\\]\n\n\n\n\n\n\n\n\n\nNote6.2 Actuarial notations\n\n\n\n\n\\({}_{t}q_{x}:= F_x(t)\\)\n\\({}_{t}p_{x}:=1-{}_{t}q_{x}=S_x(t)\\)\n\\(q_{x}:={}_{1}q_{x}\\)\n\\(p_{x}:={}_{1}p_{x}\\)\n\n\n\n\n\n\n\n\n\nNote6.3 Survival probabilities relations\n\n\n\n\nWe have \\[\n\\begin{aligned}\nS_x(t) &= \\mathbb{P}(T_x&gt;t) = \\mathbb{P}(T&gt;x+t\\mid T&gt;x)\\\\\n&=\\frac{\\mathbb{P}(T&gt;x+t)}{\\mathbb{P}(T&gt;x)}=\\frac{S(x+t)}{S(x)}.\n\\end{aligned}\n\\tag{7.2}\\]\nIn actuarial notations, \\[\n{}_{t}p_{x}=\\frac{{}_{x+t}p_{0}}{{}_{x}p_{0}}.\n\\]\nTherefore, \\[\n{}_{s+t}p_{x}=\\frac{{}_{x+s+t}p_{0}}{{}_{x}p_{0}}=\\frac{{}_{x+s}p_{0}}{{}_{x}p_{0}}\\cdot\n\\frac{{}_{x+s+t}p_{0}}{{}_{x+s}p_{0}}={}_{s}p_{x}\\cdot {}_{t}p_{x+s}.\n\\] As a result, \\[\n{}_{s+t}p_{x}={}_{s}p_{x}\\cdot {}_{t}p_{x+s}\n={}_{t}p_{x}\\cdot {}_{s}p_{x+t}.\n\\tag{7.3}\\]\nThis (obvious) property is called the consistency condition.\n\n\n\n\n\n\n\n\n\nNote6.4 The force of mortality\n\n\n\n\nThe force of mortality \\(\\mu_x\\) represents the instantaneous rate of mortality at a certain age \\(x\\in[0,\\mathfrak{w} ]\\): \\[\n\\mu_x = \\lim_{h\\to0} \\frac1h \\mathbb{P}(T\\leq x+h\\mid T&gt;x).\n\\tag{7.4}\\]\nBy (7.1), \\(F_x(0)=0\\) and \\[\n\\begin{aligned}\n\\mu_x &= \\lim_{h\\to0} \\frac1h \\bigl( F_x(h)-F_x(0) \\bigr)\\\\\n&=F_x'(0)=\\dfrac{d}{dt} \\bigl( {}_{t}q_{x} \\bigr)\\biggr\\rvert_{t=0}.\n\\end{aligned}\n\\tag{7.5}\\]\nConsider the probability density function of \\(T\\): \\[\nf(t):=F'(t).\n\\tag{7.6}\\] Then, one gets from (7.1): \\[\n\\mu_x = \\frac{F'(x)}{1-F(x)}= \\frac{f(x)}{1-F(x)}.\n\\tag{7.7}\\]\nThe term “force of mortality” is mainly used in actuarial science. In engineering, the term failure rate is in use, and in statistics, it is called the hazard function.\nSince \\(S(x)=1-F(x)\\), one can rewrite further: \\[\n\\mu_x=-\\, \\frac{S'(x)}{S(x)}=-\\, \\frac{d}{dx} \\bigl( \\ln S(x) \\bigr).\n\\tag{7.8}\\]\n\n\n\n\n\n\n\n\n\nTip6.5 Remark\n\n\n\nThe following interpretation may be useful: since \\(F_x(h)={}_{h}q_{x}\\), we have \\[\n{}_{h}q_{x}\\approx \\mu_x \\cdot h.\n\\tag{7.9}\\]\n\n\n\n\n\n\n\n\nNote6.6 Probability density function of \\(T_x\\)\n\n\n\n\nWe consider \\[\nf_x(t)=\\dfrac{d}{dt} F_x(t).\n\\tag{7.10}\\]\nWe have then, by (7.1), \\[\n\\begin{aligned}\nf_x(t)& = \\dfrac{d}{dt} \\frac{F(x+t)-F(x)}{S(x)}= \\frac{F'(x+t)}{S(x)}\\\\\n& = \\frac{F'(x+t)}{S(x+t)}\\frac{S(x+t)}{S(x)}\n\\end{aligned}\n\\] and since \\(F'(y)=1-S'(y)\\), we can use (7.8) and (7.2) to continue: \\[\n\\begin{aligned}\n&=-\\frac{S'(x+t)}{S(x+t)}S_x(t)\\\\& =S_x(t)\\mu_{x+t},\n\\end{aligned}\n\\] i.e., for \\(0\\leq t\\leq \\mathfrak{w} -x\\), \\[\nf_x(t)=S_x(t)\\mu_{x+t}={}_{t}p_{x} \\cdot \\mu_{x+t}.\n\\tag{7.11}\\]\n\nFrom (7.11), we have \\[\n\\begin{aligned}\n\\int_0^t {}_{s}p_{x} \\cdot \\mu_{x+s}\\,ds&=\n\\int_0^t f_x(s)\\,ds = \\int_0^t \\dfrac{d}{dt} F_x(s)\\,ds\\\\\n& = F_x(t)-F_x(0) =F_x(t);\n\\end{aligned}\n\\] i.e. \\[\n{}_{t}q_{x}= \\int_0^t {}_{s}p_{x} \\cdot \\mu_{x+s}\\,ds.\n\\tag{7.12}\\]\n\n\n\n\n\n\n\n\nNote6.7 Integral expressions\n\n\n\nWe found in (7.12) an integral expression for \\({}_{t}q_{x}\\). Consider now another one, for \\({}_{t}p_{x}\\). By (7.8), \\[\n\\mu_{x+s} = -\\frac{S'(x+s)}{S(x+s)} =-\\frac{d}{ds} \\ln S(x+s),\n\\] hence, integrating in \\(s\\in[0,t]\\) and using (7.2), \\[\n\\begin{aligned}\n-\\int_0^t \\mu_{x+s}\\,ds &= \\Bigl[\\ln S(x+s)\\Bigr]_0^t=\\ln \\frac{S(x+t)}{S(x)}\\\\\n& = \\ln S_x(t)=\\ln{}_{t}p_{x}.\n\\end{aligned}\n\\] Therefore, \\[\n{}_{t}p_{x} = \\exp\\biggl(-\\int_0^t \\mu_{x+s}\\,ds \\biggr).\n\\tag{7.13}\\]\n\n\n\n\n\n\n\n\nTip6.8 Remark\n\n\n\nFormula (7.13) can be also obtained by considering a time-non-homogeneous MJP with states \\(1\\), , and \\(2\\), Dead, and the transition rate \\(\\mu_t\\). Then \\[\n{}_{t}p_{x}=p_{\\overline{1,1}}(x,x+t)=\\exp\\biggl(-\\int_{x}^{x+t}\\mu_s\\,ds\\biggr),\n\\] that is nothing but (7.13), by a change of variables.\n\n\n\n\n\n\n\n\nNote6.9 Life table functions\n\n\n\n\n\\(l_x\\) denotes the expected number of lives at (integer) age \\(x\\in[0,\\mathfrak{w}]\\).\n\\(d_x\\) is the expected number of deaths between the ages of \\(x\\) and \\(x+1\\).\nThe following formulas holds: \\[\nd_x= l_x-l_{x+1};\n\\tag{7.14}\\]\n\n\\[\np_x=\\dfrac{l_{x+1}}{l_x};\n\\tag{7.15}\\]\n\\[\nq_x=1-p_x=1-\\dfrac{l_{x+1}}{l_x}=\\dfrac{d_x}{l_x};\n\\tag{7.16}\\]\n\\[\n{}_{t}p_{x}= \\dfrac{l_{x+t}}{l_x};\n\\tag{7.17}\\]\n\\[\n{}_{t}q_{x} = 1-{}_{t}p_{x}=\\dfrac{l_x-l_{x+t}}{l_x}.\n\\tag{7.18}\\]\n\n\n\n\n\n\n\n\nNote6.10 Justification of formula (7.18)\n\n\n\nLet \\(Y_x\\) be the random variable of the alive individuals of age \\(x\\), so that \\[\nl_x=\\mathbb{E}(Y_x), \\quad x\\in \\mathbb{Z}_+.\n\\] Then, by the property of the conditional expectation \\[\nl_{x+1}=\\mathbb{E}(Y_{x+1})=\\mathbb{E}\\bigl( \\mathbb{E}(Y_{x+1} \\mid Y_x=l_x) \\bigr).\n\\] Next, \\(Z_x:=\\mathbb{E}(Y_{x+1} \\mid Y_x=l_x)\\) is a random variable which satisfies the binomial law: there are \\(l_x\\) individuals of age \\(x\\) each of them may survive in the next year (independently from others) with probability \\(p_x\\) and die with probability \\(q_x=1-p_x\\), i.e. e.g. \\[\n\\mathbb{P}(Z_x = k) = \\binom{l_x}{k} (p_x)^k (q_x)^{l_x-k}.\n\\] We know from Probability course that the expectation of a binomial random variable is the product of the number of possible trials and the probability of “success”, therefore, \\[\nl_{x+1}=\\mathbb{E}(Y_{x+1}) = \\mathbb{E} (Z_x) = l_x p_x,\n\\] that implies (7.18).\n\n\n\n\n\n\n\n\nImportant6.11 Theorem: Uniform distribution of deaths\n\n\n\nIf deaths are uniformly distributed between the ages of \\(x\\) and \\(x+1\\), then, for all \\(t\\in[0,1]\\): \\[\n{}_{t}q_{x}=t \\cdot q_{x}.\n\\tag{7.19}\\]\n\nProof. Since the number of deaths is uniformly distributed, \\(l_{x+t}\\in[l_{x+1},l_x]\\) for all \\(t\\in[0,1]\\) and \\(l_{x+t}= (1-t)l_{x}+t l_{x+1}\\),\ntherefore, \\[\n{}_{t}q_{x}=\\dfrac{l_x-l_{x+t}}{l_x}=\\dfrac{t l_x - tl_{x+1}}{l_x}\n= t(1-p_x)=tq_x,\n\\] that proves the statement.\n\n\n\n\n\n\n\n\n\nTip6.12 Remark: Constant force of mortality assumption\n\n\n\nAnother assumption for the ages between \\(x\\) and \\(x+1\\) is that the force of mortality remains constant: \\[\n\\mu_{x+s} = \\mu_x, \\quad s\\in[0,1).\n\\tag{7.20}\\] In this case, by (7.13), one has \\[\n{}_{t}p_{x} = e^{-t\\mu_x} =\n\\bigl( e^{-1\\cdot \\mu_x}\\bigr)^t\n=(p_x)^t.\n\\tag{7.21}\\] Therefore, \\[\n{}_{t}q_{x}=1 - e^{-t\\mu_x} \\neq t\n(1-e^{-\\mu_x})= t q_x.\n\\tag{7.22}\\] However, if \\(\\mu_x\\approx 0\\), then \\({}_{t}q_{x}\\approx t\\mu_x \\approx t q_x\\).\n\n\n\n\n\n\n\n\nNote6.13 Analogue of consistency condition\n\n\n\nThe consistency condition (7.3) is actually nothing but the conditional probability identity. It’s counterpart for \\({}_{t}q_{x}\\) reads as follows: \\[\n{}_{t+s}q_{x}= {}_{s}q_{x}+{}_{s}p_{x}\\cdot{}_{t}q_{x+s}.\n\\tag{7.23}\\] The interpretations is as follows: to die within the next \\(t+s\\) years the person may either die in the next \\(s\\) years or survive in the next \\(s\\) years but die within next \\(t\\) years thereafter.\nFormula (7.23) can be derived rigorously from the law of the full probability (do this by yourself!) or just from (7.1): \\[\n\\begin{aligned}\n{}_{t+s}q_{x}&=\n\\frac{F(x+t+s)-F(x)}{1-F(x)}\\\\\n&= \\frac{F(x+t+s)-F(x+s)}{1-F(x)}\n+\\frac{F(x+s)-F(x)}{1-F(x)}\\\\\n&= \\frac{F(x+t+s)-F(x+s)}{1-F(x+s)}\\frac{1-F(x+s)}{1-F(x)}\n\\\\&\\quad +\\frac{F(x+s)-F(x)}{1-F(x)}\\\\\n& = {}_{t}q_{x+s}\\cdot{}_{x}p_{s} + {}_{x}q_{s},\n\\end{aligned}\n\\] where we used that, by (7.2), \\[\n\\frac{1-F(x+s)}{1-F(x)} = \\frac{S(x+s)}{S(x)}={}_{s}p_{x}.\n\\]\n\n\n\n\n\n\n\n\nNote6.14 Central rate of mortality\n\n\n\nThe central rate of mortality at age \\(x\\) is the ration of the number of deaths over the year of age \\(x\\) to \\(x+1\\) to the average number of lives then: \\[\nm_x=\\dfrac{d_x}{\\displaystyle\\int_0^1 l_{x+t}\\,dt}.\n\\tag{7.24}\\] We can also rewrite this: \\[\nm_x= \\frac{q_x}{\\displaystyle\\int_0^1 {}_{t}p_{x} \\,dt}=\n\\dfrac{\\displaystyle\\int_0^1 {}_{t}p_{x} \\mu_{x+t}\\,dt}{\\displaystyle\\int_0^1 {}_{t}p_{x} \\,dt}&lt;q_x.{}\n\\tag{7.25}\\]\n\n\n\n\n\n\n\n\nNote6.15 Complete expectation of life\n\n\n\nThe expected future lifetime after age \\(x\\in[0,\\mathfrak{w}]\\) is defined as follows: \\[\n\\mathring{e}_x: = \\mathbb{E}(T_x).\n\\tag{7.26}\\] Using the definition of the expectation for a continuous random variable, we have, by (7.11), \\[\n\\begin{aligned}\n\\mathbb{E}(T_x)&= \\int_0^{\\mathfrak{w}-x} t f_x(t)\\,dt\\\\\n& = \\int_0^{\\mathfrak{w}-x} t \\cdot \\dfrac{d}{dt} F_x(t)\\,dt\n\\\\\n&= -\\int_0^{\\mathfrak{w}-x} t \\cdot \\dfrac{d}{dt} {}_{t}p_{x} \\,dt\n\\end{aligned}\n\\] and then we integrate by parts \\[\n\\begin{aligned}\n&=- \\Bigl[t {}_{t}p_{x} \\Bigr]_0^{\\mathfrak{w}-x}+\n\\int_0^{\\mathfrak{w}-x} {}_{t}p_{x} \\,dt\\\\\n&= \\int_0^{\\mathfrak{w}-x} {}_{t}p_{x} \\,dt,\n\\end{aligned}\n\\] as $ {}{-x}p{x}=(T_{x}&gt;-x)=0$.\nSince \\[\n{}_{t}p_{x}=0 \\quad\\text{for } t&gt;\\mathfrak{w}-x\n\\] as well, one can rewrite: \\[\n\\mathring{e}_x = \\mathbb{E}(T_x)=\\int_0^\\infty {}_{t}p_{x} \\,dt.\n\\tag{7.27}\\]\n\n\n\n\n\n\n\n\nImportant6.16 Theorem: Monotonicity of the lifetime\n\n\n\nFunction \\(x+\\mathring{e}_x\\) is increasing in \\(x\\), i.e. \\[\nx+\\mathring{e}_x&lt;y+\\mathring{e}_y, \\quad x&lt;y.\n\\tag{7.28}\\] In other words, expectation for the age of death \\(T=x+T_x\\) increases when the person managed to live more.\n\nProof. We have \\[\n\\begin{aligned}\n\\frac{d}{dx}\\mathring{e}_x &= \\int_0^\\infty \\frac{d}{dx} {}_{t}p_{x}\\,dt=\n\\int_0^\\infty \\frac{d}{dx} \\frac{S(x+t)}{S(x)}\\,dt\\\\\n& = \\int_0^\\infty \\frac{S'(x+t)S(x)-S'(x)S(x+t)}{(S(x))^2}\\,dt\\\\\n& =\\int_0^\\infty \\frac{S'(x+t)}{S(x)}\\,dt\n+\\mu_x\\int_0^\\infty \\frac{S(x+t)}{S(x)}\\,dt \\\\\n& = -1+\\mu_x \\mathring{e}_x.\n\\end{aligned}\n\\] Therefore, \\[\n\\frac{d}{dx} \\left( \\mathring{e}_x + x \\right) = \\mu_x \\mathring{e}_x&gt;0.\n\\]\n\n\n\n\n\n\n\n\n\nTip6.17 Remark\n\n\n\nThe previous statement may be confusing if we look at equalities \\(T=x+T_x\\) and \\(T=y+T_y\\), so then we would expect that $ (T)=x+_x$ and \\(\\mathbb{E}(T)=y+\\mathring{e}_y\\). Apparently, these are two different random variables both (actually, wrongly) denoted by \\(T\\). Namely, when we write \\(T=x+T_x\\), we consider the random lifetime \\(T\\) conditional that a person was alive at age \\(x\\), it is measurable w.r.t. \\(\\sigma\\)-algebra generated by ages \\(\\leq x\\). The random variable \\(\\tilde{T}=y+T_y\\) is, hence, different.\n\n\n\n\n\n\n\n\nNote6.18 Curtate expectation of life\n\n\n\nThe curtate future lifetime of a life age \\(x\\) is \\[\nK_x=[T_x],\n\\] where \\([y]\\) denotes the integer part of \\(y\\), i.e. \\(y\\) is rounded down to the nearest integer.\nWe have then, because of the continuity of \\(T\\) (i.e. of \\(F(t)\\)), \\[\n\\begin{aligned}\n\\mathbb{P}(K_x=k)& =\\mathbb{P}(k\\leq T_x&lt;k+1)\\\\\n&=\\mathbb{P}(k&lt;T_x\\leq k+1)\\\\&={}_{k}p_{x}\\cdot q_{x+k}.\n\\end{aligned}\n\\] We define the curtate expectation of life as follows: \\[\ne_x=\\mathbb{E}(K_x).\n\\tag{7.29}\\] We have, hence, \\[\n\\begin{aligned}\ne_x &= \\sum_{k=0}^{[\\mathfrak{w}-x]} k\\cdot \\mathbb{P}(K_x=k)\n=\\sum_{k=1}^{[\\mathfrak{w}-x]} \\sum_{j=1}^k 1\\cdot \\mathbb{P}(K_x=k)\\\\\n&=\\sum_{j=1}^{[\\mathfrak{w}-x]}\\sum_{k=j}^{[\\mathfrak{w}-x]}\\mathbb{P}(K_x=k)= \\sum_{j=1}^{[\\mathfrak{w}-x]}\\mathbb{P}(K_x\\geq j).\n\\end{aligned}\n\\] Since \\(\\mathbb{P}(K_x\\geq j)= \\mathbb{P}(T_x\\geq j)={}_{j}p_{x}\\) (\\(=0\\) for \\(j&gt;[\\mathfrak{w}-x]\\)), \\[\ne_x =\\mathbb{E}(K_x) =\\sum_{j=1}^{\\infty}{}_{j}p_{x}.\n\\tag{7.30}\\]\n\n\n\n\n\n\n\n\nNote6.19 Simple parametric survival models\n\n\n\n\nExponential model : \\[\n\\mu_x=\\mu, \\quad \\text{for all } x\\in[0,\\mathfrak{w}].\n\\] Then \\[\n{}_{t}p_{x}=S_x(t)=e^{-\\mu t}\n\\] Note that \\[\nf(t) = S(t)\\mu_t = \\mu e^{-\\mu t}.\n\\]\nWeibull model : \\[\n\\mu_x=\\alpha \\beta x^{\\beta-1}, \\quad \\alpha, \\beta&gt;0.\n\\] Note that \\(\\mu_x\\) is increasing if \\(\\beta&gt;1\\) and decreasing if \\(\\beta\\in(0,1)\\). \\(\\beta=1\\) corresponds to the exponential model. We have \\[\n{}_{t}p_{x}=S_x(t)=\\exp\\Bigl( - \\alpha \\bigl((x+t)^\\beta -x^\\beta\\bigr) \\Bigr).\n\\] In particular, \\[\nS(t)=e^{- \\alpha t^\\beta},\n\\] hence, \\[\nf(t) = \\alpha \\beta t^{\\beta-1}e^{- \\alpha t^\\beta}.\n\\] Parameter \\(\\beta\\) is called shape and \\(\\alpha\\) is called scale.\nGompertz model : \\[\n\\mu_x= b c^x, \\quad b,c&gt;0.\n\\]\n\nIf \\(c&gt;1\\), then \\(\\mu_x\\) is increasing; and if \\(c\\in(0,1)\\), then \\(\\mu_x\\) is decreasing. \\(c=1\\) corresponds to the exponential model.\nParameter \\(b&gt;0\\) is called rate. Often the hazard rate is written for \\(c=e^\\gamma\\), where \\(\\gamma=\\ln c\\in\\mathbb{R}\\) is called shape.\nWe have \\[\n{}_{t}p_{x} = S_x(t)=g ^{c^x(c^t-1)},\n\\] where \\[\ng=\\exp\\Bigl(-\\frac{b}{\\ln c}\\Bigr).\n\\]\nWe have also: \\[\nf(t) = \\mu_t S(t)= bc^t g^{c^t-1}.\n\\]\n\nGompertz–Makeham model : \\[\n\\mu_x= a+b c^x, \\quad a,b,c&gt;0.\n\\] Then \\[\n{}_{t}p_{x} =S_x(t)=e^{-at} g ^{c^x(c^t-1)},\n\\] where \\(g\\) is the same as above. Then \\[\nf(t) = (a+b c^t) e^{-at} g ^{c^t-1}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Survival models</span>"
    ]
  },
  {
    "objectID": "Ch-08.html",
    "href": "Ch-08.html",
    "title": "8  Estimations of lifetime distributions",
    "section": "",
    "text": "Note7.1 Why do we need to estimate\n\n\n\n\nThe main problem about the force of mortality \\(\\mu_t\\) (a.k.a. the hazard rate \\(\\lambda_t\\)) is that it is unknown in practice.\nInstead, one has data that is the result of some observations. Observations are made at discrete moments of time.\nWe consider the case when the age \\(x\\) with which persons are entering into the observation is either irrelevant or uniform (i.e. the whole observed population has “almost” the same age).\nHence, time starts at \\(0\\) with the start of observation and all changes are recorded at discrete moments of time only.\nLet \\(t_1&lt;t_2&lt;t_3&lt;\\ldots\\) be ordered moments of time when the records where updated (e.g. days when deaths happened). Stress that the number of events at each \\(t_j\\) may be bigger than \\(1\\).\nThe moments of time are random. Our basic assumption is that all \\(t_j\\) have independent identical distribution.\nWe assume hence that \\(T\\) changes at times \\(t_1, t_2,\\ldots\\) only, hence, \\(F(t)=\\mathbb{P}(T\\leq t)\\) is a step-function: it has jumps at \\(t_j\\), \\(j\\geq1\\), and it takes constant value in between.\n\n\n\n\n\n\n\n\n\nNote7.2 Discrete hazard function\n\n\n\nWe define \\[\n\\lambda_j = \\mathbb{P}(T=t_j \\mid T\\geq t_j), \\quad j\\geq1.\n\\]\nThen \\[\n\\lambda_j=\\frac{\\mathbb{P}(T=t_j)}{\\mathbb{P}(T\\geq t_j)}=\n\\frac{\\mathbb{P}(T=t_j)}{\\sum\\limits_{k\\geq j}\\mathbb{P}(T=t_k)}.\n\\]\n\n\n\n\n\n\n\n\nNote7.3 Estimator for the discrete hazard function\n\n\n\n\nLet \\(d_j\\) be the number of deaths at time \\(t_j\\), and \\(n_j\\) be the number of persons in the risk set prior to the time \\(t_j\\).\nStress that all persons censored (i.e. excluded from the observation) before time \\(t_j\\) are not counted in \\(n_j\\).\nWe assume also that any person censored at time \\(t_j\\) is actually censored immediately after that time, and hence is counted in \\(n_j\\).\nThe estimator for \\(\\lambda_j\\) is then \\[\n\\hat{\\lambda}_j=\\frac{d_j}{n_j}.\n\\tag{8.1}\\]\nWe will see below why this estimator is relevant.\n\n\n\n\n\n\n\n\n\nNote7.4 Discrete survival function\n\n\n\n\nSince \\(S(t)=1-F(t)\\), the survival function \\(S(t)\\) is also constant on each \\([t_j,t_{j+1})\\), \\(j\\geq 1\\): namely, for \\(t\\in [t_j,t_{j+1})\\), \\[\n\\begin{aligned}\nS(t)&=\\mathbb{P}(T&gt;t)=\\mathbb{P}(T&gt;t_j)\\\\\n& = \\mathbb{P}(T&gt;t_j\\mid T&gt;t_{j-1})\\mathbb{P}(T&gt;t_{j-1})\\\\\n& = \\mathbb{P}(T&gt;t_j\\mid T&gt;t_{j-1})\\\\\n&\\qquad\\times \\mathbb{P}(T&gt;t_{j-1}\\mid T&gt;t_{j-2})\\mathbb{P}(T&gt;t_{j-2})\\\\\n& = (1-\\lambda_j)(1-\\lambda_{j-1})\\ldots\n(1-\\lambda_{2})\\mathbb{P}(T&gt;t_{1})\\\\\n&= \\prod_{i=1}^j (1-\\lambda_i),\n\\end{aligned}\n\\tag{8.2}\\] where we used that \\(t_1\\) is the first recorded moment of time, i.e. \\(T\\geq t_1\\), hence, \\[\n\\mathbb{P}(T&gt;t_{1})=1-\\mathbb{P}(T=t_{1})=1-\\lambda_1.\n\\]\nTherefore, the value of \\(S(t)\\) on the interval \\(t\\in[t_{j},t_{j+1})\\) is the value on the previous interval \\([t_{j-1},t_j)\\) multiplied by \\(1-\\lambda_j\\).\nOne can aso rewrite (8.2) as follows: \\[\nS(t)=\\prod_{j:t_j\\leq t} (1-\\lambda_j).\n\\tag{8.3}\\]\n\n\n\n\n\n\n\n\n\nNote7.5 Kaplan–Meier estimate of the survival function\n\n\n\n\nKaplan–Meier estimate \\(\\hat{S}(t)\\) of the survival function \\(S(t)\\) is just the replacing of \\(\\lambda_i\\) in (8.3) by \\(\\hat{\\lambda}_j\\) given by (8.1): \\[\n\\hat{S}(t)=\\prod_{j:t_j\\leq t} (1-\\hat{\\lambda_j})=\\prod_{j:t_j\\leq t} \\Bigl(1-\\frac{d_j}{n_j}\\Bigr).\n\\tag{8.4}\\]\nWe are going to discuss now in which sense \\(\\hat{\\lambda}_j\\) and \\(\\hat{S}(t)\\) are relevant estimators.\n\n\n\n\n\n\n\n\n\nCaution7.6 Definition: Likelihood\n\n\n\nLet \\(X:\\Omega\\to S\\) be a discrete random variable dependent on a parameter. Consider the probability that \\(X=x\\in S\\) given the specific value \\(\\theta\\) of the parameter. It can be denoted \\(\\mathbb{P}_\\theta(X=x)\\), or \\(\\mathbb{P}(X=x\\mid \\theta)\\) (despite \\(\\theta\\) does not need to be random).\nThe likelihood function is the function \\(\\mathcal{L}(\\theta\\mid x)\\) of \\(\\theta\\) which depends on \\(x\\), and it is given by \\[\n\\mathcal{L}(\\theta\\mid x)=\\mathbb{P}(X=x\\mid \\theta).\n\\] We say that \\(\\mathcal{L}\\) is the likelihood function, given the outcome \\(x\\) of the random variable \\(X\\).\n\n\n\n\n\n\n\n\nTip7.7 Remark: Likelihood is not probability\n\n\n\nStress that \\(\\mathcal{L}(\\theta \\mid x)\\) is not \\(\\mathbb{P}(\\theta \\mid X=x)\\). First, the latter object does not have sense if \\(\\theta\\) is not random. However, even for a random variable \\(\\theta\\), \\[\n\\begin{aligned}\n\\mathbb{P}(\\theta=\\theta_0\\mid X=x)&=\n\\frac{\\mathbb{P}( X=x\\mid \\theta=\\theta_0) \\mathbb{P}(\\theta=\\theta_0)}{\\mathbb{P}(X=x)}\\\\&= \\mathcal{L}(\\theta_0)\\frac{\\mathbb{P}(\\theta=\\theta_0)}{\\mathbb{P}(X=x)},\n\\end{aligned}\n\\] according to Bayes’ theorem.\n\n\n\n\n\n\n\n\nNote7.8 Likelihood function of the data\n\n\n\n\nFix \\(j\\geq 1\\), and consider the random variable \\(X\\) that is the vector of all \\(d_i\\) and \\(n_i\\) for \\(1\\leq i\\leq j\\).\nLet \\(\\theta\\) be the vector of all \\(\\lambda_i\\), \\(1\\leq i\\leq j\\). Then \\[\n\\begin{aligned}\n\\mathcal{L}(\\theta\\mid X)&=\\mathbb{P}\\bigl(X=(d_i,n_i:i\\leq j)\\bigm\\vert \\theta=(\\lambda_i:i\\leq j)\\bigr)\n\\\\&= \\prod_{i=1}^j \\binom{n_i}{d_i}\\lambda_i^{d_i}(1-\\lambda_i)^{n_i-d_i}.\n\\end{aligned}\n\\]\nA natural question is to find the maximal likelihood: \\[\n\\theta_*=\\mathrm{argmax}\\, \\mathcal{L}(\\theta\\mid X),\n\\] i.e. \\(\\mathcal{L}(\\theta_*\\mid X)=\\max\\limits_{\\theta} \\mathcal{L}(\\theta\\mid X)\\).\nThe maximal likelihood is the value of the parameter that maximizes the probability to observe the data.\nSince logarithm is an increasing function, \\[\n\\mathrm{argmax}\\, \\mathcal{L}(\\theta\\mid X)=\\mathrm{argmax}\\, \\ln \\mathcal{L}(\\theta\\mid X).\n\\]\nWe have \\[\n\\begin{aligned}\n\\ln \\mathcal{L}(\\theta\\mid X)&=\n\\sum_{i=1}^j \\bigl(d_i\\ln \\lambda_i + (n_i-d_i)\\ln (1-\\lambda_i)\\bigr)\\\\\n&\\quad +\\sum_{i=1}^j\\ln\\binom{n_i}{d_i}.\n\\end{aligned}\n\\]\nThe last summand is a constant in \\(\\theta\\) (for the given data \\(X\\)), hence it will not influence the maximal likelihood. One has \\[\n\\begin{aligned}\n\\frac{\\partial \\ln \\mathcal{L}(\\theta\\mid X)}{\\partial \\lambda_i} =\\frac{d_i}{\\lambda_i} - \\frac{n_i-d_i}{1-\\lambda_i}.\n\\end{aligned}\n\\]\nThe derivative is \\(0\\) for \\(\\lambda_i= \\dfrac{d_i}{n_i}\\).\nMoreover, it can be checked that \\[\n\\theta = \\Bigl(\\dfrac{d_i}{n_i}\\Bigr)_{i\\leq j}=(\\hat{\\lambda}_i)_{i\\leq j}\n\\] is indeed the point of maximum of \\(\\ln \\mathcal{L}(\\theta\\mid X)\\).\n\n\n\n\n\n\n\n\n\nNote7.9 Nelson–Aalen estimate of the integrated hazard\n\n\n\n\nLet \\(\\mu_t\\) be the hazard function (a.k.a. the force of mortality). Then the function \\[\n\\Lambda_t:=\\int_0^t\\mu_s\\,ds\n\\] is called the integrated hazard function.\nRecall that \\[\nS_x(t)={}_{t}p_{x}=\\exp\\biggl(-\\int_0^t\\mu_{x+s}\\,ds\\biggr),\n\\] and \\(S(t)=S_0(t)=\\mathbb{P}(T&gt;t)\\) (where \\(0\\), recall, does not need to be an absolute age, but rather an initial time of the observation). Therefore, \\[\nS(t)=\\exp(-\\Lambda_t).\n\\]\nThe Nelson–Aalen estimate of the integrated hazard is \\[\n\\hat{\\Lambda}_t = \\sum_{j: t_j\\leq t} \\dfrac{d_j}{n_j};\n\\] and the corresponding estimate of the survival function is \\[\n\\hat{S}(t)=\\exp\\bigl(-\\hat{\\Lambda_t}\\bigr).\n\\]\n\n\n\n\n\n\n\n\n\nNote7.10 Likelihood function for continuous \\(T\\)\n\n\n\nFor a continuous random variable \\(T\\), the likelihood function is usually defined through their densities \\(f(t\\mid\\theta)\\) rather than probabilities \\(F(T\\mid\\theta)\\). In particular, if deaths happened at times \\(t_1,t_2,\\ldots\\) then (assuming that all lives had independent identical distributions): \\[\n\\mathcal{L}(\\theta|\\textrm{data}):=\n\\prod_{t_j} f(t_j\\mid \\theta).\n\\] If the time of death is a discrete random variable, its density is just the probability, i.e. the formula is agreed with the previous one.\nIf, however, a live was censored at a time \\(t_k\\), it means that it was still alive at that time, so we have to multiply the likelihood by the probability \\(S(t_k\\mid \\theta)\\).\nTherefore: \\[\n\\mathcal{L}(\\theta|\\textrm{data}):=\n\\prod_{\\textrm{times of deaths}} f(t_j\\mid \\theta)\\prod_{\\textrm{times of censoring}} S(t_j\\mid \\theta).\n\\] Since, by (1.11), \\(f(t)=S(t)\\lambda(t)\\), where \\(\\lambda(t)=\\mu_t\\) is the hazard rate, we can also rewrite: \\[\n\\mathcal{L}(\\theta|\\textrm{data}):=\n\\prod_{\\textrm{times of deaths}} \\lambda(t_j\\mid \\theta)\\prod_{\\textrm{all times}} S(t_j\\mid \\theta).\n\\]\nStress that some \\(t_j\\) may be equal.\nA common use of such likelihood is for the estimation of parameters for the parametric models.\n\n\n\n\n\n\n\n\nWarning7.11 Example\n\n\n\nSuppose we expect that certain data corresponds to the constant force of mortality \\(\\mu_t\\equiv \\mu\\) (or \\(\\lambda(t)\\equiv\\mu\\) in another notations). Then \\(S(t)=\\exp(-\\mu t)\\), and we have (here \\(\\theta=\\mu\\)) \\[\n\\begin{aligned}\n\\mathcal{L}(\\mu) &= \\prod_{\\textrm{times of deaths}} \\mu\\prod_{\\textrm{all times}} \\exp(-\\mu t) \\\\\n& = \\mu^k \\exp\\Bigl(-\\mu \\sum_{j}t_j\\Bigr),\n\\end{aligned}\n\\] where \\(k\\) is the total number of the observed deaths and \\(\\{t_j\\}\\) are times of all events (both deaths and censoring). Then \\[\nl(\\mu) = \\ln \\mathcal{L}(\\mu) = k\\ln \\mu - \\mu \\sum_{j}t_j,\n\\] and hence, \\[\nl'(\\mu) =\\frac{k}{\\mu} - \\sum_{j}t_j, \\quad L''(\\mu) = -\\frac{k}{\\mu^2}&lt;0.\n\\] Thus, \\[\n\\mu_* = \\frac{k}{\\displaystyle\\ \\sum_{j}t_j\\ }\n\\] is the estimator for \\(\\mu\\) which maximize the likelihood.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estimations of lifetime distributions</span>"
    ]
  },
  {
    "objectID": "Ch-09.html",
    "href": "Ch-09.html",
    "title": "9  Proportional hazards models",
    "section": "",
    "text": "Note8.1 Covariates\n\n\n\nCovariates are characteristics of the participants of the experiment under consideration. For example, age, sex, type of treatment, level of medication, severity of symptoms and so on.\nMathematically, we represent the values of covariates as a vector \\(z\\) with numerical components. Then e.g. the hazard rate \\(\\lambda_t\\) (a.k.a the force of mortality) depend on \\(z\\): \\(\\lambda_t=\\lambda(t,z)\\).\n\n\n\n\n\n\n\n\nNote8.2 Proportional hazards models\n\n\n\nA common assumption about hazard is that the dependence on time and on the covariates can be factorized (i.e. time and covariates are not “twisted”): \\[\n\\lambda(t,z)=\\lambda_0(t)g(z).\n\\] The function \\(\\lambda_0(t)\\) is called then the baseline hazard.\nThis is called a proportional hazard model (in short, a PH model). The reason for the name is that the proportion of of hazard rates for different covariates does not depend on time: \\[\n\\frac{\\lambda(t,z_1)}{\\lambda(t,z_2)} = \\frac{g(z_1)}{g(z_2)}.\n\\]\n\n\n\n\n\n\n\n\nNote8.3 A parametric PH model\n\n\n\n\nA parametric PH model that uses the Gompertz distribution can be defined as follows.\nWe consider the hazard rate \\(\\lambda_t=bc^t\\), \\(c&gt;0\\), that depends on covariates vector \\(z\\): \\[\n\\lambda(t,z)=b(z)c^t, \\qquad b(z):=\\exp(\\beta\\cdot z),\n\\] where \\(\\beta\\) is a vector of regression coefficients, and \\(\\beta\\cdot z\\) denotes the scalar (a.k.a. inner) product.\nSince both \\(c&gt;0\\) and \\(b(z)&gt;0\\), it is useful also to consider \\[\n\\ln \\lambda(t,z)=t\\,\\ln c+\\beta\\cdot z.\n\\]\n\n\n\n\n\n\n\n\n\nNote8.4 The Cox PH model\n\n\n\n\nThe Cox PH models proposes the following form of the hazard function \\[\n\\lambda(t,z)=\\lambda_0(t)\\exp(\\beta\\cdot z).\n\\tag{9.1}\\]\n\\(\\lambda_0(t)\\) is the baseline hazard, \\(\\beta\\) is the vector of regression parameters.\nWhen \\(\\beta\\) is known (or found), one can get the ratio of hazards for different covariates: \\[\n\\frac{\\lambda(t,z_1)}{\\lambda(t,z_2)} = \\exp(\\beta\\cdot (z_1-z_2)).\n\\] This tells, in particular, how much larger is the force of mortality (a.k.a. hazard) for a covariate with respect to another one.\nThe traditional way to find (or rather, select) \\(\\beta\\) is to maximize the partial likelihood. Namely, let deaths are recorded at moments of time \\(t_j\\), \\(1\\leq j\\leq k\\), and suppose first that there is one death at each \\(t_j\\), i.e. \\(d_j=1\\) for all \\(j\\). Let \\(z_j\\) be the covariates vector of the life died at time \\(t_j\\). Let \\(R(t_j)\\) be the set of all lives at risk to die prior to time \\(t_j\\), \\(1\\leq j\\leq k\\). The partial likelihood is defined then as follows: \\[\nL(\\beta) = \\prod_{j=1}^k \\frac{\\exp(\\beta\\cdot z_j)}{\\sum\\limits_{i\\in R_{(t_j)}}\\exp(\\beta\\cdot z_i)}.\n\\]\nIn the case when some \\(d_j&gt;1\\), the exact calculations are complicate, hence the following Breslow’s approximation is in use: \\[\nL(\\beta) = \\prod_{j=1}^k \\frac{\\exp(\\beta\\cdot z_j)}{\\Bigl(\\sum\\limits_{i\\in R_{(t_j)}}\\exp(\\beta\\cdot z_i)\\Bigr)^{d_j}}.\n\\]\n\n\n\n\n\n\n\n\n\nTip8.5 Remark\n\n\n\nIt is common to include all censored at time \\(t_j\\) lives to \\(R(t_j)\\), assuming that the censoring occurs just after the observed deaths.\n\n\n\n\n\n\n\n\nWarning8.6 Example\n\n\n\nA study is being conducted, using the Cox regression model, into how going to gym affects a patient’s future lifetime after they had a serious heart attack. The Cox model is considered with a parameter \\(\\beta\\in\\mathbb{R}\\) and the covariate \\(z=1\\) if the patient was a gym-visitor, and \\(z=0\\) otherwise. The data about \\(9\\) patients is available in the table. Patients are labelled as “censored” if they were still alive at the end of the study of if their death was not considered to be attributable to the decease. Time is measured in weeks.\nWe are going to find the partial likelihood function of \\(\\beta\\) and the maximal partial likelihood estimator \\(\\beta^*\\).\nSort the table by the time of death and highlight the non-censored deaths:\nPatient 7 (a gym-visitor) died first after 4 weeks; before time 4 there are 6 gym-visitors and 2 non-gym-visitors. It gives the factor \\[\n    L_1(\\beta)=\\frac{e^{\\beta\\cdot1}}{6e^{\\beta\\cdot1}+2e^{\\beta\\cdot0}}=\\frac{e^\\beta}{6e^\\beta+2}.\n\\]\nPatient 5 (a non-gym-visitor) died the second, at time 6; before time 6 remained 4 gym-visitors and 2 non-gym-visitors. It gives the factor \\[\n    L_2(\\beta)=\\frac{e^{\\beta\\cdot0}}{4e^{\\beta\\cdot1}+2e^{\\beta\\cdot0}}=\\frac{1}{4e^\\beta+2}.\n\\]\nPatient 3 (a gym-visitor) died the last among non-censored, at time 9. By that time, there were 2 gym-visitors and 1 non-gym-visitor, it gives \\[\n    L_3(\\beta)=\\frac{e^{\\beta\\cdot1}}{2e^{\\beta\\cdot1} +e^{\\beta\\cdot0}}=\\frac{e^\\beta}{2e^\\beta +1}.   \n\\] Therefore, \\[\n\\begin{aligned}\nL(\\beta) &=     L_1(\\beta)L_2(\\beta)L_3(\\beta)=\\frac{e^\\beta}{6e^\\beta+2}\n\\frac{1}{4e^\\beta+2}\n\\frac{e^\\beta}{2e^\\beta +1}\\\\&=\\frac{e^{2\\beta}}{4(3e^\\beta+1)(2e^\\beta+1)^2}.\n\\end{aligned}\n\\]\nThe point of maximum of \\(L(\\beta)\\) is the same as for \\[\n\\begin{aligned}\n    l(\\beta):&= \\ln \\frac{e^{2\\beta}}{(3e^\\beta+1)(2e^\\beta+1)^2}\\\\& = 2\\beta - \\ln(3e^\\beta+1)- 2\\ln (2e^\\beta+1).\n\\end{aligned}\n\\] We have \\[\n\\begin{aligned}\n    l'(\\beta)&=2-\\frac{3e^\\beta}{3e^\\beta+1}-2\\cdot \\frac{2e^\\beta}{2e^\\beta+1}\\\\\n    &= \\frac{2(3e^\\beta+1)(2e^\\beta+1)-3e^\\beta(2e^\\beta+1)-4e^\\beta(3e^\\beta+1)}{(3e^\\beta+1)(e^\\beta+1)^2},\n\\end{aligned}\n\\] thus \\(l'(\\beta)=0\\) implies \\[\n    -6e^{2\\beta}+3e^\\beta+2=0.  \n\\]\nTaking \\(x=e^\\beta&gt;0\\), we get \\[\n    6x^2-3x-2=0, \\quad x=\\frac{3+\\sqrt{57}}{12},\\quad\n    \\beta^*=\\ln \\frac{3+\\sqrt{57}}{12}.\n\\]\nCheck that this is indeed the point of maximum: \\[\n\\begin{aligned}\n    L''(\\beta) &=-3\\cdot \\frac{e^\\beta (3e^\\beta+1) -3e^\\beta\\cdot e^\\beta}{(3e^\\beta+1)^2}\\\\&\\quad -   4\\cdot \\frac{e^\\beta (2e^\\beta+1) -2e^\\beta\\cdot e^\\beta}{(2e^\\beta+1)^2}\\\\\n    &= -\\frac{3}{(3e^\\beta+1)^2}-\n    \\frac{4}{(2e^\\beta+1)^2}&lt;0\n\\end{aligned}\n\\] for all \\(\\beta\\), in particular, for \\(\\beta=\\beta^*\\). Hence \\(\\beta^*\\) is the point of maximum.\n\n\n\n\n\n\n\n\nTip8.7 Remark\n\n\n\nIf the choose the found value \\(\\beta=\\beta^*\\) for the hazard rate (9.1), then \\[\n\\frac{\\lambda(t,z=1)}{\\lambda(t,z=0)}= e^{\\beta^*}=\\frac{3+\\sqrt{57}}{12}\\approx 0.879,\n\\] i.e., according to the conducted study, the force of mortality for gym-visitor is approximately 88% of the force of mortality for non-gym-visitors (ignoring all other possible covariates: age, gender etc.)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Proportional hazards models</span>"
    ]
  },
  {
    "objectID": "Ch-10.html",
    "href": "Ch-10.html",
    "title": "10  Exposed to risk",
    "section": "",
    "text": "Note9.1 Exposed to risk\n\n\n\n\nThe \\(1\\)-year “mortality rate” \\[\nq_x={}_{1}q_{x}=\\mathbb{P}(T\\leq x+1 \\mid T&gt;x)\n\\] depends naturally on the age \\(x\\).\nSometimes one can ignore this dependence if the data uniform in age, or when we are interested in the time lives survived within the trial rather than in the absolute time (in this case we assumed that \\(x=0\\)).\nIn the latter case, we could still take into account the age, considering it as a covariate.\nHowever, it is often important to deal with various ages, and numerous covariates become non-feasible.\nA natural estimation for \\(\\mu_x\\) would be \\[\n\\hat{\\mu}_x=\\frac{\\text{expected number of deaths of lives aged $x$}}{\\text{number of lives aged $x$}},\n\\] where both parts of the fraction are considered on time interval \\([x,x+1)\\).\nThe denominator, however, changes within the unit time (e.g. if time is measured in years, the number will decrease within the year).\nThe number of lives aged \\(x\\) at the beginning of the year interval is called the exposed to risk and is denoted \\(E_x\\).\nOn practice, one prefers to use an averaged number of lives within the year interval. This quantity is called the central exposed to risk, and is denoted \\(E_x^c\\).\nFor example, if there are \\(100\\) lives of age \\(x\\) and if it is know that in average \\(1\\) life dies within the next year, then \\(E_x^c=99.5\\) (that corresponds to the “number” of lives at the center (middle) of the year time-interval, hence, the name).\nHowever, in practice, we do not deal with lives of exactly the same age, hence, some lives at a moment of time \\(s\\) may give an input to \\(E_x^c\\), but at time \\(t&gt;s\\) they may impact \\(E_{x+1}^c\\) if the birthday day took place during the time-interval \\((s,t)\\).\nIt is also important that the start of the trial (investigation) and end of the trial are not the birthday days, hence, the time-intervals when a particular life makes an input to a certain \\(E_x^c\\) may vary.\nBefore considering an example, we formulate the following principle of correspondence:\n\na life alive at time \\(t\\) should be included in the (central) exposed to risk number \\(E_x\\) (impact \\(E_x^c\\)) at age \\(x\\) at time \\(t\\) if and only if were that life to die immediately, they would be counted in the deaths number \\(d_x\\) at age \\(x\\).\n\n\n\n\n\n\n\n\nWarning9.2 Example\n\n\n\nSuppose that a mortality investigation covers the period \\(1\\) January \\(2015\\) to \\(31\\) December \\(2017\\). In this study, the “age” means “age last birthday”. Consider the data about \\(2\\) males involved in the study.\nTherefore, the first male life joined the study at age \\(31\\) last birthday. His life will be counted in the following central exposed to risk quantities at different moments of time (we assume here that the day of exit is not counted):\n\\(E_{31}^c\\): from 01/01/15 to 24/04/15\n\\(E_{32}^c\\): from 25/04/15 to 24/04/16\n\\(E_{33}^c\\): from 25/04/16 to 29/10/16\nSimilarly, the second male life joined the study at age \\(34\\) last birthday. The contribution to the central exposed risk, hence, are:\n\\(E_{34}^c\\): from 22/07/17 to 03/09/17\n\\(E_{35}^c\\): from 04/09/17 to 03/12/17\n\n\n\n\n\n\n\n\nNote9.3 Census approximation to \\(E_x^c\\)\n\n\n\n\nLet \\(P_{x,t}\\) denote the number of lives under observation aged \\(x\\) last birthday, at time \\(t\\).\nSuppose we have observation over \\(N+1\\) calendar years of all deaths between ages \\(x\\) and \\(x+1\\). Then \\[\nE_x^c = \\int_0^{N+1} P_{x,t}\\,dt.\n\\]\nUnder the assumption that \\(P_{x,t}\\) changes linearly in \\(t\\) within each year, the value of \\(E_x^c\\) can be approximated by the trapezium rule : \\[\nE_x^c\\approx \\frac12 \\sum_{t=0}^{N} \\bigl(P_{x,t}+P_{x,t+1}\\bigr).\n\\]\n\n\n\n\n\n\n\n\n\nTip9.4 Remark\n\n\n\nRecall that, in the above, we used “age \\(x\\)” as the “age \\(x\\) last birthday”, the value of \\(d_x\\) should be then calculated accordingly.\nOne can also use the “nearest birthday” approach or the “next birthday” approach, each would require recalculation of \\(d_x\\).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exposed to risk</span>"
    ]
  }
]